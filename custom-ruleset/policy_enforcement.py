"""Reusable IAM policy enforcement plugin for ADK-based agents."""

from __future__ import annotations

import contextlib
from contextvars import ContextVar
import hashlib
import json
import os
import re
import threading
import time
from collections import OrderedDict
from typing import Any, Dict, Iterable, Optional, Sequence, Tuple

import jwt
import google.generativeai as genai
import requests
from google.adk.plugins.base_plugin import BasePlugin

try:
    from google.genai.types import Content, Part
    from google.adk.models.llm_response import LlmResponse
except ImportError:
    Content = None
    Part = None
    LlmResponse = None


GLOBAL_REQUEST_TOKEN: ContextVar[str | None] = ContextVar(
    "global_request_token", default=None
)


class PolicyEnforcementPlugin(BasePlugin):
    """IAM ê¸°ë°˜ ì •ì±… ì§‘í–‰ í”ŒëŸ¬ê·¸ì¸."""

    _DEFAULT_MODEL = "gemini-2.0-flash"
    _DEFAULT_REPLAY_TTL_SECONDS = 5.0
    _DEFAULT_USER_ERROR_MESSAGE = "ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    _SECRET_PATTERNS = [
        (re.compile(r"(Authorization\s*:\s*Bearer\s+)[A-Za-z0-9\-\._~+/=]+", re.IGNORECASE), r"\1***"),
        (re.compile(r"(Bearer\s+)[A-Za-z0-9\-\._~+/=]+", re.IGNORECASE), r"\1***"),
        (re.compile(r"(api[_-]?key\s*[=:]\s*)([^\s]+)", re.IGNORECASE), r"\1***"),
        (re.compile(r"(token\s*[=:]\s*)([^\s]+)", re.IGNORECASE), r"\1***"),
        (re.compile(r"(secret\s*[=:]\s*)([^\s]+)", re.IGNORECASE), r"\1***"),
    ]
    _PATH_PATTERN = re.compile(r"((?:[A-Za-z]:)?[\\/][^\s]+)")

    def __init__(
        self,
        *,
        agent_id: str,
        gemini_api_key: Optional[str],
        policy_server_url: str,
        log_server_url: str,
        initial_auth_token: Optional[str] = None,
        initial_context: Optional[Any] = None,
    ) -> None:
        super().__init__(name=f"policy_enforcement_{agent_id}")
        self.agent_id = agent_id
        self.policy_server_url = policy_server_url.rstrip("/")
        self.log_server_url = log_server_url.rstrip("/")
        self.gemini_api_key = gemini_api_key
        self._models: Dict[str, Any] = {}
        
        # [Stateless] ì „ì—­ self.policy ëŒ€ì‹  ìºì‹œë§Œ ìœ ì§€
        self._policy_cache: Dict[str, Dict[str, Any]] = {}
        
        # [í•„ìˆ˜] ë ˆê±°ì‹œ í˜¸í™˜ì„± ë° ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•œ ë¹ˆ ê°ì²´
        self.policy: Dict[str, Any] = {}

        self._jwt_secret = os.getenv("JWT_SECRET") or os.getenv("SECRET_KEY")
        self._jwt_public_key = os.getenv("JWT_PUBLIC_KEY")
        self._jwt_algorithm = os.getenv("JWT_ALGORITHM") or os.getenv("ALGORITHM") or "HS256"
        self._jwt_audience = os.getenv("JWT_AUDIENCE")
        self._last_auth_token: str | None = None
        self._captured_token_hint: str | None = None
        self._last_policy_fetch_token: str | None = None
        self._replay_cache: "OrderedDict[str, float]" = OrderedDict()
        self._replay_lock = threading.Lock()
        ttl_env = os.getenv("POLICY_PLUGIN_REPLAY_TTL")
        try:
            self._replay_ttl = float(ttl_env) if ttl_env else self._DEFAULT_REPLAY_TTL_SECONDS
        except ValueError:
            self._replay_ttl = self._DEFAULT_REPLAY_TTL_SECONDS

        self._ingest_initial_auth(initial_auth_token, initial_context)

        if gemini_api_key:
            genai.configure(api_key=gemini_api_key)
            self._models[self._DEFAULT_MODEL] = genai.GenerativeModel(self._DEFAULT_MODEL)

    # ------------------------------------------------------------------
    # [ì•ˆì „ì¥ì¹˜] agent_executorê°€ í˜¸ì¶œí•˜ë”ë¼ë„ ì£½ì§€ ì•Šê²Œ ë¹ˆ ë©”ì„œë“œ ìœ ì§€
    # ------------------------------------------------------------------
    def fetch_policy(
        self,
        *,
        tool_context: Any = None,
        tool_args: Optional[Dict[str, Any]] = None,
        force: bool = False,
    ) -> None:
        pass

    # ------------------------------------------------------------------
    # Policy retrieval helpers
    # ------------------------------------------------------------------
    def _get_policy_for_tenant(self, tenant_str: str) -> Dict[str, Any]:
        """
        [HTTP API ëª¨ë“œ] í…Œë„ŒíŠ¸ ì •ì±…ì„ HTTP APIë¡œ ìš”ì²­í•˜ì—¬ ë¡œë“œ
        Docker í™˜ê²½ì„ ê³ ë ¤í•˜ì—¬ ì—¬ëŸ¬ URLì„ ì‹œë„
        """
        # 1. ìºì‹œì— ìˆìœ¼ë©´ ë¦¬í„´
        if tenant_str in self._policy_cache:
            return self._policy_cache[tenant_str]

        merged_policy = {
            "template": "merged_policy",
            "tenant": tenant_str,
            "allowed_list": [] 
        }
        
        valid_targets = set()
        merged_agent_map = {}
        policy_found = False

        for tenant_read in tenant_str.split(","):
            tenant_clean = tenant_read.strip()
            if not tenant_clean: continue
            
            # API URL ì„¤ì • (í™˜ê²½ ë³€ìˆ˜ë¡œ ì œì–´ ê°€ëŠ¥, Docker í™˜ê²½ ê³ ë ¤)
            # ìš°ì„ ìˆœìœ„: í™˜ê²½ë³€ìˆ˜ > Docker ì„œë¹„ìŠ¤ëª… > host.docker.internal > localhost
            base_urls = [
                os.environ.get("POLICY_API_URL", "").rstrip("/"),  # í™˜ê²½ ë³€ìˆ˜
                "http://solution:3000",                            # Docker Compose ì„œë¹„ìŠ¤ëª…
                "http://attager-solution:3000",                    # Docker ì»¨í…Œì´ë„ˆëª…
                "http://host.docker.internal:3000",                # Docker Desktop
                "http://localhost:3000"                             # ë¡œì»¬ í™˜ê²½
            ]
            
            # ë¹ˆ ë¬¸ìì—´ ì œê±°
            base_urls = [url for url in base_urls if url]
            
            params = {
                "tenant": tenant_clean,
                "author": "security manager"
            }
            
            data = None
            successful_url = None
            
            # ì—¬ëŸ¬ URLì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹œë„
            for base_url in base_urls:
                api_url = f"{base_url}/api/rulesets/tenant-template"
                try:
                    print(f"[DEBUG] ì •ì±… API ìš”ì²­ ì‹œë„: {api_url}?tenant={tenant_clean}&author=security+manager")
                    response = requests.get(api_url, params=params, timeout=5)
                    
                    if response.status_code == 200:
                        data = response.json()
                        successful_url = api_url
                        print(f"[DEBUG] âœ“ API ì‘ë‹µ ì„±ê³µ: {successful_url}")
                        break
                    else:
                        print(f"[DEBUG] âœ— HTTP {response.status_code} from {api_url}")
                        
                except requests.exceptions.Timeout:
                    print(f"[DEBUG] âœ— íƒ€ì„ì•„ì›ƒ: {api_url}")
                    continue
                except requests.exceptions.ConnectionError:
                    print(f"[DEBUG] âœ— ì—°ê²° ì‹¤íŒ¨: {api_url}")
                    continue
                except Exception as e:
                    print(f"[DEBUG] âœ— ì˜¤ë¥˜ ({api_url}): {e}")
                    continue
            
            # ë°ì´í„° ì²˜ë¦¬
            if data:
                policy_found = True
                raw_list = data.get("allowed_list", [])
                print(f"[DEBUG] API ì‘ë‹µ ìˆ˜ì‹  ì„±ê³µ. í•­ëª© ìˆ˜: {len(raw_list)}")
                
                for rule in raw_list:
                    raw_aid = rule.get("agent_id")
                    
                    if raw_aid:
                        # [Strict Mode] agent_idë¥¼ ìˆëŠ” ê·¸ëŒ€ë¡œ ì €ì¥
                        clean_aid = str(raw_aid).strip()
                        valid_targets.add(clean_aid)
                        
                        tools = rule.get("allowed_tools", [])
                        if clean_aid in merged_agent_map:
                            existing_tools = set(merged_agent_map[clean_aid]["allowed_tools"])
                            existing_tools.update(tools)
                            merged_agent_map[clean_aid]["allowed_tools"] = list(existing_tools)
                        else:
                            merged_agent_map[clean_aid] = {
                                "agent_id": clean_aid,
                                "allowed_tools": list(set(tools))
                            }
            else:
                print(f"[ERROR] ëª¨ë“  API URL ì‹œë„ ì‹¤íŒ¨ (tenant: {tenant_clean}). ì‹œë„í•œ URL: {base_urls}")

        if policy_found:
            merged_policy["allowed_list"] = list(merged_agent_map.values())
            merged_policy["_valid_targets"] = valid_targets 
            
            self._policy_cache[tenant_str] = merged_policy
            
            print(f"[DEBUG] ìµœì¢… ìŠ¹ì¸ëœ ì—ì´ì „íŠ¸ ëª©ë¡: {valid_targets}")
            return merged_policy
        
        return {}

    # ------------------------------------------------------------------
    # ADK callbacks
    # ------------------------------------------------------------------
    def _check_allowlist_rule(
        self,
        tool_name: str,
        policy: Dict[str, Any],
        tenant_id: str,
        tool_args: Dict[str, Any]
    ) -> Optional[str]:
        
        if not policy:
            return f"No policy defined for tenant '{tenant_id}'."

        allowed_list = policy.get("allowed_list", [])
        
        # 1. [ìê¸° ì‹ë³„] Strict Match (ëŒ€ì†Œë¬¸ì êµ¬ë¶„)
        my_id_strict = self.agent_id.strip()

        my_rule = next(
            (
                item for item in allowed_list 
                if str(item.get("agent_id", "")).strip() == my_id_strict
            ), 
            None
        )

        if not my_rule:
            return f"Access Denied: Agent '{self.agent_id}' is not defined in the policy."

        # 2. [ë„êµ¬ ê¶Œí•œ í™•ì¸]
        my_allowed_tools = my_rule.get("allowed_tools", [])
        
        if tool_name not in my_allowed_tools:
            return f"Tool '{tool_name}' is NOT allowed for agent '{self.agent_id}'."

        # 3. [ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì „ìš©] call_remote_agent íƒ€ê²Ÿ ê²€ì¦
        if tool_name == "call_remote_agent":
            target_agent = tool_args.get("agent_name")
            if not target_agent:
                return "Missing 'agent_name' argument."
            
            # [ìˆ˜ì •ë¨] .lower() ì œê±°! ì…ë ¥ëœ íƒ€ê²Ÿ ì´ë¦„ ê·¸ëŒ€ë¡œ ë¹„êµ (Strict Mode)
            target_strict = str(target_agent).strip()
            
            valid_targets = policy.get("_valid_targets", set())
            
            if target_strict not in valid_targets:
                return f"Access Denied: Target '{target_agent}' is not a valid agent in this tenant."

        return None
    
    async def before_model_callback(
        self,
        *,
        callback_context: Any,
        llm_request: Any,
        **kwargs: Any,
    ) -> Optional[Any]:
        """Validate user prompts before the LLM is invoked."""
        self._capture_auth_from_context(callback_context)
        replay_block = self._guard_soft_replay(callback_context or {}, llm_request)
        if replay_block is not None:
            return replay_block
        self.fetch_policy(tool_context=callback_context)
        if not self._policy_enabled():
            return None

        prompt_rules = self._get_prompt_rules()
        if not prompt_rules:
            return None

        user_prompt = self._extract_user_message(llm_request)
        if not user_prompt:
            return None

        rule = prompt_rules[0]
        system_prompt = rule.get("system_prompt", "")
        model_name = rule.get("model")

        verdict = await self._inspect_with_llm(system_prompt, user_prompt, model_name)
        print(f"[PolicyPlugin][{self.agent_id}] í”„ë¡¬í”„íŠ¸ íŒì •: {verdict}")

        if verdict != "SAFE":
            self._send_log(
                {
                    "source": "agent",
                    "agent_id": self.agent_id,
                    "policy_type": "prompt_validation",
                    "prompt": user_prompt,
                    "verdict": "VIOLATION",
                    "message": f"[{self.agent_id}] í”„ë¡¬í”„íŠ¸ ì •ì±… ìœ„ë°˜: ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ê°€ IAM ì •ì±…ì„ ìœ„ë°˜í–ˆìŠµë‹ˆë‹¤.",
                }
            )
            violation_message = (
                f"[{self.agent_id}] ì£„ì†¡í•©ë‹ˆë‹¤. ê·€í•˜ì˜ ìš”ì²­ì´ ì‹œìŠ¤í…œ ì •ì±…ì— ìœ„ë°˜ë˜ì–´ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n"
                "ìœ„ë°˜ ì‚¬ìœ : ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì—ì„œ ì •ì˜í•œ ë³´ì•ˆ ë° ì‚¬ìš© ì •ì±…ì„ ì¤€ìˆ˜í•˜ì§€ ì•ŠëŠ” ìš”ì²­ì…ë‹ˆë‹¤.\n"
                "ì •ì±…ì— ë¶€í•©í•˜ëŠ” ìš”ì²­ì„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤."
            )
            return self._create_llm_response(violation_message)
        
        # ì •ìƒ í†µê³¼ ë¡œê·¸ ê¸°ë¡
        self._send_log(
            {
                "source": "agent",
                "agent_id": self.agent_id,
                "policy_type": "prompt_validation",
                "prompt": user_prompt[:100] + "..." if len(user_prompt) > 100 else user_prompt,
                "verdict": "PASS",
                "message": f"[{self.agent_id}] í”„ë¡¬í”„íŠ¸ ê²€ì¦ í†µê³¼",
            }
        )

        
        incoming_token = self._extract_auth_token(callback_context, {})
        
        if incoming_token:
            if hasattr(callback_context, "state") and isinstance(callback_context.state, dict):
                callback_context.state["auth_token"] = incoming_token
            elif hasattr(callback_context, "session") and hasattr(callback_context.session, "state"):
                 callback_context.session.state["auth_token"] = incoming_token
        
        return None

    async def before_tool_callback(
        self,
        *,
        tool: Any,
        tool_args: Dict[str, Any],
        tool_context: Any,
        callback_context: Any = None,
        **kwargs: Any,
    ) -> Optional[Dict[str, Any]]:
        
        ctx = callback_context or tool_context
        
        claims = self._get_auth_claims(ctx, tool_args)
        current_tenant = self._extract_tenant_from_claims(claims)

        if not current_tenant or current_tenant.startswith("<"):
            return {"error": "Access Denied: No valid tenant found."}

        request_policy = self._get_policy_for_tenant(current_tenant)
        
        if not request_policy:
            return {"error": f"Access Denied: No policy found for tenant '{current_tenant}'."}

        tool_name = getattr(tool, "name", str(tool))
        
        violation = self._check_allowlist_rule(
            tool_name, 
            request_policy, 
            current_tenant, 
            tool_args
        )

        if violation:
            user_safe_message = self.sanitize_error_message(violation)
            log_safe_violation = self.sanitize_error_message(violation, audience="log")
            self._send_log(
                {
                    "source": "agent",
                    "agent_id": self.agent_id,
                    "policy_type": "tool_validation",
                    "tool_name": tool_name,
                    "tool_args": tool_args,
                    "verdict": "BLOCKED",
                    "message": f"[{self.agent_id}] íˆ´ ì°¨ë‹¨: {log_safe_violation}",
                    "target_agent": tool_args.get("agent_name", ""),
                }
            )
            print(f"[PolicyPlugin][{self.agent_id}] íˆ´ ì°¨ë‹¨: {log_safe_violation}")
            return {"error": user_safe_message}

        # ì •ìƒ í†µê³¼ ë¡œê·¸ ê¸°ë¡
        self._send_log(
            {
                "source": "agent",
                "agent_id": self.agent_id,
                "policy_type": "tool_validation",
                "tool_name": tool_name,
                "verdict": "PASS",
                "message": f"[{self.agent_id}] íˆ´ ê²€ì¦ í†µê³¼: {tool_name}",
                "target_agent": tool_args.get("agent_name", ""),
            }
        )
        print(f"[PolicyPlugin] âœ… ìŠ¹ì¸ë¨({current_tenant}): {tool_name}")
        return None

    def _guard_soft_replay(self, callback_context: Any, llm_request: Any) -> Optional[Any]:
        payload_hash = self._hash_llm_request(llm_request)
        if not payload_hash:
            return None

        email = self._extract_replay_subject(callback_context)
        if not email:
            return None

        key = self._build_replay_key(email, payload_hash)
        now = time.monotonic()
        replay_detected = False

        with self._replay_lock:
            self._cleanup_replay_cache(now)
            last_seen = self._replay_cache.get(key)
            if last_seen is None:
                self._replay_cache[key] = now
            else:
                if now - last_seen <= self._replay_ttl:
                    replay_detected = True
                else:
                    self._replay_cache[key] = now
            self._replay_cache.move_to_end(key)

        if not replay_detected:
            return None

        reason = "Repeated message payload detected within replay TTL"
        self._send_log(
            {
                "source": "agent",
                "agent_id": self.agent_id,
                "policy_type": "replay_protection",
                "verdict": "BLOCKED",
                "message": f"[{self.agent_id}] ë¦¬í”Œë ˆì´ ì°¨ë‹¨: {reason}",
                "tool_name": "",
            }
        )
        violation_message = (
            "ìš”ì²­ì´ ë„ˆë¬´ ì§§ì€ ì‹œê°„ ì•ˆì— ë°˜ë³µë˜ì–´ soft replay ì •ì±…ì— ì˜í•´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
            "ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        )
        return self._create_llm_response(violation_message)

    # ... (ë‚˜ë¨¸ì§€ helper í•¨ìˆ˜ë“¤ì€ ê·¸ëŒ€ë¡œ ë‘ì„¸ìš”) ...
    # _policy_enabled, _get_prompt_rules, _get_tool_rules
    # _extract_user_message, _inspect_with_llm, _resolve_model
    # _check_tool_rule, _create_llm_response, _send_log
    # _ingest_initial_auth, _log_policy_fetch, _capture_auth_from_context
    # _extract_auth_token, _extract_token_from_container, _get_auth_claims
    # _decode_jwt, _log_token_inspection, _log_policy_binding
    # _normalize_required_roles, _extract_roles_from_claims
    # _extract_tenant_from_claims, _roles_satisfied, _sanitize_bearer

    # ------------------------------------------------------------------
    # Internal helpers
    # ------------------------------------------------------------------
    def _policy_enabled(self) -> bool:
        if not self.policy:
            return False
        enabled = self.policy.get("enabled", True)
        if isinstance(enabled, str):
            enabled = enabled.lower() not in {"false", "0", "off"}
        return bool(enabled)

    def _get_prompt_rules(self) -> Sequence[Dict[str, Any]]:
        rules = self.policy.get("prompt_validation_rules", []) or []
        if not rules:
            policies = self.policy.get("policies")
            if isinstance(policies, dict):
                prompt_validation = policies.get("prompt_validation") or {}
                system_prompt = prompt_validation.get("system_prompt", "")
                model = prompt_validation.get("model")
                enabled = prompt_validation.get("enabled", True)
                if system_prompt:
                    rules = [
                        {
                            "system_prompt": system_prompt,
                            "model": model,
                            "enabled": enabled,
                        }
                    ]

        enabled_rules = []
        for rule in rules:
            enabled = rule.get("enabled", True)
            if isinstance(enabled, str):
                enabled = enabled.lower() not in {"false", "0", "off"}
            if enabled and rule.get("system_prompt"):
                enabled_rules.append(rule)
        return enabled_rules

    def _get_tool_rules(self) -> Dict[str, Dict[str, Any]]:
        rules = self.policy.get("tool_validation_rules")

        if not rules:
            policies = self.policy.get("policies")
            if isinstance(policies, dict):
                tool_validation = policies.get("tool_validation") or {}
                enabled = tool_validation.get("enabled", True)
                if isinstance(enabled, str):
                    enabled = enabled.lower() not in {"false", "0", "off"}
                if not enabled:
                    return {}
                rules = tool_validation.get("rules")

        if isinstance(rules, dict):
            return rules
        return {}

    def _extract_user_message(self, llm_request: Any) -> str:
        message = ""
        if hasattr(llm_request, "contents") and llm_request.contents:
            for content in reversed(llm_request.contents):
                role = getattr(content, "role", None)
                if role == "user" and getattr(content, "parts", None):
                    for part in content.parts:
                        text = getattr(part, "text", None)
                        if text:
                            message += text
                    break
        return message

    async def _inspect_with_llm(
        self,
        system_prompt: str,
        user_prompt: str,
        model_name: Optional[str],
    ) -> str:
        if not system_prompt or not self.gemini_api_key:
            return "SAFE"

        model = self._resolve_model(model_name)
        if model is None:
            return "SAFE"

        try:
            inspect_prompt = (
                f"{system_prompt}\n\n"
                f"ê²€ì‚¬ ëŒ€ìƒ í”„ë¡¬í”„íŠ¸:\n\"{user_prompt}\"\n\n"
                "ì‘ë‹µì€ SAFE ë˜ëŠ” VIOLATION ë‘˜ ì¤‘ í•˜ë‚˜ë¡œë§Œ í•´ì£¼ì„¸ìš”."
            )
            response = model.generate_content([inspect_prompt])
            verdict = (response.text or "").strip().split()[0].upper()
            return verdict if verdict in {"SAFE", "VIOLATION"} else "SAFE"
        except Exception as exc:  # pragma: no cover - runtime LLM failures
            print(f"[PolicyPlugin] LLM ê²€ì¦ ì‹¤íŒ¨: {exc}")
            return "SAFE"

    def _resolve_model(self, model_name: Optional[str]):
        name = model_name or self._DEFAULT_MODEL
        if name in self._models:
            return self._models[name]
        if not self.gemini_api_key:
            return None
        try:
            model = genai.GenerativeModel(name)
            self._models[name] = model
            return model
        except Exception as exc:  # pragma: no cover - runtime model resolution issues
            print(f"[PolicyPlugin] ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨({name}): {exc}")
            return self._models.get(self._DEFAULT_MODEL)

    def _check_tool_rule(
        self,
        tool_name: str,
        tool_args: Dict[str, Any],
        rule: Dict[str, Any],
        tool_context: Any,
    ) -> Optional[str]:
        allowed_agents = rule.get("allowed_agents")
        if allowed_agents:
            agent_name = tool_args.get("agent_name") or tool_args.get("agent")
            if agent_name and agent_name not in allowed_agents:
                return f"Agent '{agent_name}' is not allowed for {tool_name}"

        max_task_length = rule.get("max_task_length")
        if isinstance(max_task_length, int):
            task = tool_args.get("task", "") or ""
            if len(task) > max_task_length:
                return f"Task length ({len(task)}) exceeds maximum ({max_task_length})"

        requires_auth = rule.get("requires_auth")
        if isinstance(requires_auth, str):
            requires_auth = requires_auth.lower() not in {"false", "0", "off"}
        if requires_auth and not self._extract_auth_token(tool_context, tool_args):
            return "Authentication required for this tool"

        required_roles = rule.get("required_roles") or rule.get("required_role")
        normalized_roles = self._normalize_required_roles(required_roles)
        if normalized_roles:
            claims = self._get_auth_claims(tool_context, tool_args)
            user_roles = self._extract_roles_from_claims(claims)
            if not user_roles:
                return "Role information missing from JWT token"
            if not self._roles_satisfied(user_roles, normalized_roles):
                return f"Tool '{tool_name}' requires role(s): {', '.join(normalized_roles)}"

        max_results = rule.get("max_results")
        if isinstance(max_results, int):
            limit = tool_args.get("limit")
            if isinstance(limit, int) and limit > max_results:
                return f"Requested limit ({limit}) exceeds maximum ({max_results})"

        return None

    def _create_llm_response(self, message: str):
        if Content and Part and LlmResponse:
            try:
                response_content = Content(role="model", parts=[Part(text=message)])
                return LlmResponse(content=response_content)
            except Exception as exc:  # pragma: no cover
                print(f"[PolicyPlugin] LlmResponse ìƒì„± ì‹¤íŒ¨: {exc}")
        raise RuntimeError(message)

    def _send_log(self, payload: Dict[str, Any]) -> None:
        payload = self._sanitize_payload(dict(payload))
        log_url = f"{self.log_server_url}/api/logs"
        print(f"[PolicyPlugin] ğŸ“¤ ë¡œê·¸ ì „ì†¡ ì‹œë„: {log_url}")
        print(f"[PolicyPlugin] ğŸ“¦ í˜ì´ë¡œë“œ: {payload}")
        try:
            response = requests.post(
                log_url,
                json=payload,
                timeout=2,
            )
            print(f"[PolicyPlugin] âœ… ë¡œê·¸ ì „ì†¡ ê²°ê³¼: HTTP {response.status_code}")
            if response.status_code >= 400:
                print(f"[PolicyPlugin] âš ï¸ ë¡œê·¸ ì„œë²„ ì‘ë‹µ: {response.text[:200]}")
        except requests.exceptions.ConnectionError as e:
            print(f"[PolicyPlugin] âŒ ë¡œê·¸ ì„œë²„ ì—°ê²° ì‹¤íŒ¨ ({log_url}): {e}")
        except requests.exceptions.Timeout:
            print(f"[PolicyPlugin] â±ï¸ ë¡œê·¸ ì„œë²„ íƒ€ì„ì•„ì›ƒ ({log_url})")
        except Exception as e:
            print(f"[PolicyPlugin] âŒ ë¡œê·¸ ì „ì†¡ ì˜ˆì™¸: {type(e).__name__}: {e}")

    # ------------------------------------------------------------------
    # Authentication helpers
    # ------------------------------------------------------------------
    def _ingest_initial_auth(self, token_hint: Optional[str], context: Optional[Any]) -> None:
        env_token = (
            os.getenv("IAM_BOOTSTRAP_AUTH_TOKEN")
            or os.getenv("POLICY_BOOTSTRAP_TOKEN")
            or os.getenv("AUTH_TOKEN")
        )

        candidates = [token_hint, env_token, self._extract_token_from_container(context)]

        for candidate in candidates:
            cleaned = self._sanitize_bearer(candidate)
            if cleaned:
                self._captured_token_hint = cleaned
                self._last_auth_token = cleaned
                break

    def _log_policy_fetch(self, token: str) -> None:
        base_message = f"[PolicyPlugin] {self.agent_id} ì •ì±… ë¡œë“œ ì™„ë£Œ"

        if not token:
            print(f"{base_message} (auth_token=<none>)")
            return

        claims = self._decode_jwt(token)
        roles = self._extract_roles_from_claims(claims)
        tenant = self._extract_tenant_from_claims(claims)
        subject = claims.get("sub") or claims.get("email") or claims.get("user") or "<unknown>"
        token_preview = token if len(token) <= 18 else f"{token[:10]}...{token[-6:]}"
        print(f"{base_message} (subject={subject}, roles={roles or []}, tenant={tenant}, token={token_preview})")

    def _capture_auth_from_context(self, callback_context: Any) -> None:
        token = self._extract_token_from_container(callback_context)
        if token:
            self._captured_token_hint = token

    def _extract_auth_token(self, tool_context: Any, tool_args: Dict[str, Any]) -> str:
        # [ì§€ë¢° 3] í”ŒëŸ¬ê·¸ì¸ ë™ì‘ í™•ì¸ìš© ë¡œê·¸ (ê°ì²´ ë‚´ë¶€ êµ¬ì¡° ê³µê°œ)
        direct_token = GLOBAL_REQUEST_TOKEN.get()
        
        if direct_token:
            print(f"[3. Plugin] ContextVar ì§í†µ í„°ë„ì—ì„œ í† í° ë°œê²¬ ({direct_token[:10]}...)", flush=True)
            return self._sanitize_bearer(direct_token)
        # [ë””ë²„ê¹…] ë„ëŒ€ì²´ tool_context ì•ˆì— ë­ê°€ ë“¤ì—ˆëŠ”ì§€ ì†ì„±ì„ ë‹¤ ì°ì–´ë´…ë‹ˆë‹¤.
        try:
            attributes = dir(tool_context)
            # ë„ˆë¬´ ë§ìœ¼ë‹ˆ _ë¡œ ì‹œì‘í•˜ëŠ” ê±° ë¹¼ê³  ì¶œë ¥
            public_attrs = [a for a in attributes if not a.startswith('_')]
            print(f"[3. Plugin] Context ì†ì„± ëª©ë¡: {public_attrs}", flush=True)
        except:
            pass

        # ---------------------------------------------------------
        # [íƒìƒ‰ 1] Executorê°€ ë„£ì–´ë‘” ì„¸ì…˜ State ì°¾ê¸° (ê°•ë ¥í•œ íƒìƒ‰)
        # ---------------------------------------------------------
        possible_states = []

        # 1. tool_context.state
        if hasattr(tool_context, "state"):
            possible_states.append(tool_context.state)
        
        # 2. tool_context.session.state
        if hasattr(tool_context, "session"):
            session = getattr(tool_context, "session", None)
            if session and hasattr(session, "state"):
                possible_states.append(session.state)

        # 3. tool_context.context.state (ì¤‘ì²©ëœ ê²½ìš°)
        if hasattr(tool_context, "context"):
            inner_ctx = getattr(tool_context, "context", None)
            if inner_ctx:
                if hasattr(inner_ctx, "state"):
                    possible_states.append(inner_ctx.state)
                if hasattr(inner_ctx, "session") and hasattr(inner_ctx.session, "state"):
                    possible_states.append(inner_ctx.session.state)

        # 4. (ì¶”ê°€) attributes ë”•ì…”ë„ˆë¦¬ í™•ì¸
        if hasattr(tool_context, "attributes") and isinstance(tool_context.attributes, dict):
             possible_states.append(tool_context.attributes)

        # ìˆ˜ì§‘ëœ ëª¨ë“  state í›„ë³´êµ°ì„ ë’¤ì ¸ì„œ í† í° ì°¾ê¸°
        for state in possible_states:
            if not state: continue
            
            # dictì¸ ê²½ìš°
            if isinstance(state, dict):
                token = state.get("auth_token")
                if token:
                    print(f"[3. Plugin] â­• (Dict State) í† í°: {token[:10]}...", flush=True)
                    return self._sanitize_bearer(token)
            # objectì¸ ê²½ìš°
            elif hasattr(state, "auth_token"):
                token = getattr(state, "auth_token")
                if token:
                    print(f"[3. Plugin] â­• ì°¾ì•˜ë‹¤! (Obj State) í† í°: {token[:10]}...", flush=True)
                    return self._sanitize_bearer(token)

        # ---------------------------------------------------------
        # [íƒìƒ‰ 2] ë„êµ¬ ì¸ì(Arguments)ì—ì„œ ì°¾ê¸°
        # ---------------------------------------------------------
        tool_args = tool_args or {}
        candidates = [
            tool_args.get("auth_token"),
            tool_args.get("token"),
            tool_args.get("Authorization"),
            tool_args.get("authorization"),
        ]

        # ---------------------------------------------------------
        # [íƒìƒ‰ 3] ê¸°íƒ€ ì»¨í…Œì´ë„ˆ ì¬ê·€ íƒìƒ‰ (í—¤ë” ë“±)
        # ---------------------------------------------------------
        candidates.append(self._extract_token_from_container(tool_context))
        candidates.append(self._extract_token_from_container(getattr(tool_context, "metadata", None)))

        if self._captured_token_hint:
            candidates.append(self._captured_token_hint)

        if self._last_auth_token:
            candidates.append(self._last_auth_token)

        for candidate in candidates:
            cleaned = self._sanitize_bearer(candidate)
            if cleaned:
                print(f"[3. Plugin] â­• (Container/Args) í† í°: {cleaned[:10]}...", flush=True)
                return cleaned
        
        print(f"[3. Plugin] âŒ ì‹¤íŒ¨: í† í°ì´ ì—†ìŠµë‹ˆë‹¤.", flush=True)
        return ""

    def _extract_token_from_container(self, container: Any, _visited: Optional[set[int]] = None) -> str:
        # [ë””ë²„ê¹…] ë“¤ì–´ì˜¤ëŠ” ìš”ì²­ì˜ í—¤ë”ë¥¼ í›”ì³ë³´ì
        if isinstance(container, dict) and "auth_token" in container:
             print(f"[3. Plugin] ì»¨í…Œì´ë„ˆ ì•ˆì— auth_token ìˆìŒ: {str(container.get('auth_token'))[:10]}...", flush=True)
        if not container:
            return ""

        if _visited is None:
            _visited = set()

        ident = id(container)
        if ident in _visited:
            return ""
        _visited.add(ident)

        if isinstance(container, dict):
            headers = container.get("headers") or container
            for key in ("Authorization", "authorization", "auth_token", "token"):
                if key in headers:
                    return self._sanitize_bearer(headers.get(key))

            for nested_key in (
                "headers",
                "metadata",
                "context",
                "raw_request",
                "request",
                "envelope",
            ):
                nested = headers.get(nested_key)
                cleaned = self._extract_token_from_container(nested, _visited)
                if cleaned:
                    return cleaned

            for value in headers.values():
                cleaned = self._extract_token_from_container(value, _visited)
                if cleaned:
                    return cleaned

        if isinstance(container, (list, tuple, set)):
            for item in container:
                cleaned = self._extract_token_from_container(item, _visited)
                if cleaned:
                    return cleaned

        for attr in ("headers", "metadata", "context", "raw_request", "request"):
            candidate = getattr(container, attr, None)
            cleaned = self._extract_token_from_container(candidate, _visited)
            if cleaned:
                return cleaned

        return ""

    def _get_auth_claims(self, tool_context: Any, tool_args: Dict[str, Any]) -> Dict[str, Any]:
        token = self._extract_auth_token(tool_context, tool_args)
        if not token:
            return {}
        claims = self._decode_jwt(token)
        if claims:
            repeated_token = token == self._last_auth_token
            self._log_token_inspection(token, claims, repeated=repeated_token)
            self._log_policy_binding(token, claims)
            self._last_auth_token = token
        return claims

    def _decode_jwt(self, token: str) -> Dict[str, Any]:
        options = {"verify_signature": bool(self._jwt_secret or self._jwt_public_key)}
        verify_args: Dict[str, Any] = {"algorithms": [self._jwt_algorithm]}

        if self._jwt_audience:
            verify_args["audience"] = self._jwt_audience

        key = self._jwt_public_key or self._jwt_secret
        try:
            if key:
                return jwt.decode(token, key=key, options=options, **verify_args)
            return jwt.decode(token, options={"verify_signature": False})
        except Exception as exc:  # pragma: no cover - runtime token parsing
            print(f"[PolicyPlugin] JWT decode ì‹¤íŒ¨: {exc}")
            return {}

    def _log_token_inspection(self, token: str, claims: Dict[str, Any], *, repeated: bool = False) -> None:
        roles = self._extract_roles_from_claims(claims)
        subject = claims.get("sub") or claims.get("email") or claims.get("user")
        token_preview = token if len(token) <= 18 else f"{token[:10]}...{token[-6:]}"
        event = "JWT ì¬ì‚¬ìš©" if repeated else "JWT ë¡œë“œ"
        print(
            "[PolicyPlugin][{}] {}: sub={}, roles={}, token={}".format(
                self.agent_id, event, subject or "<unknown>", roles or [], token_preview
            )
        )

    def _log_policy_binding(self, token: str, claims: Dict[str, Any]) -> None:
        roles = self._extract_roles_from_claims(claims)
        subject = claims.get("sub") or claims.get("email") or claims.get("user") or "<unknown>"
        token_preview = token if len(token) <= 18 else f"{token[:10]}...{token[-6:]}"
        rule_keys = sorted(self._get_tool_rules().keys())
        rule_summary = ", ".join(rule_keys) if rule_keys else "<no tool rules>"
        print(
            "[PolicyPlugin][{}] ì •ì±… ì ìš©: subject={}, roles={}, token={}, rules={}".format(
                self.agent_id, subject, roles or [], token_preview, rule_summary
            )
        )

    def _normalize_required_roles(self, required_roles: Any) -> list[str]:
        if not required_roles:
            return []
        if isinstance(required_roles, str):
            required_roles = [required_roles]
        if isinstance(required_roles, Iterable):
            return [str(role).strip().lower() for role in required_roles if str(role).strip()]
        return []

    def _extract_roles_from_claims(self, claims: Dict[str, Any]) -> list[str]:
        if not isinstance(claims, dict):
            return []
        roles: list[str] = []
        for key in ("roles", "role", "permissions", "scopes", "scope"):
            value = claims.get(key)
            if isinstance(value, str):
                roles.extend(item.strip().lower() for item in value.split() if item.strip())
            elif isinstance(value, Iterable):
                roles.extend(str(item).strip().lower() for item in value if str(item).strip())
        return roles

    def _extract_tenant_from_claims(self, claims: Dict[str, Any]) -> str:
        """
        Pydantic ìŠ¤í‚¤ë§ˆ(TenantValue)ì— ë§ì¶° í…Œë„ŒíŠ¸ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        Target Key: "tenant"
        Type: str | List[str]
        """
        if not isinstance(claims, dict):
            return "<unknown_tenant>"

        # 1. ìŠ¤í‚¤ë§ˆì— ì •ì˜ëœ ì •í™•í•œ í‚¤ 'tenant'ë¥¼ ìš°ì„  í™•ì¸
        # ì„œë²„ ìŠ¤í‚¤ë§ˆ: class TokenData(BaseModel): tenant: TenantValue | None
        val = claims.get("tenant")

        # 2. ê°’ì´ ì—†ëŠ” ê²½ìš°, ê´€ë¡€ì ì¸ ë‹¤ë¥¸ í‚¤ë“¤ë„ í™•ì¸ (í˜¹ì‹œ ëª¨ë¥´ë‹ˆ)
        if val is None:
            for fallback_key in ["tid", "tenant_id", "org_id"]:
                val = claims.get(fallback_key)
                if val: break
        
        if val is None:
            return "<no_tenant>"

        # 3. TenantValue = Union[str, List[str]] ì²˜ë¦¬
        if isinstance(val, list):
            # ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°: ë¡œê·¸ ê°€ë…ì„±ì„ ìœ„í•´ ì½¤ë§ˆë¡œ ì—°ê²°í•˜ê±°ë‚˜ ì²« ë²ˆì§¸ ê°’ ì‚¬ìš©
            # ì˜ˆ: ['a', 'b'] -> "a,b"
            return ",".join(str(v) for v in val)
        
        return str(val).strip()

    def _roles_satisfied(self, user_roles: list[str], required_roles: list[str]) -> bool:
        user_role_set = {role.lower() for role in user_roles}
        return any(role.lower() in user_role_set for role in required_roles)

    @staticmethod
    def _sanitize_bearer(token: Any) -> str:
        if not token:
            return ""
        token_str = str(token).strip()
        if token_str.lower().startswith("bearer "):
            return token_str[7:].strip()
        return token_str

    # ------------------------------------------------------------------
    # Soft replay helpers
    # ------------------------------------------------------------------
    def _hash_llm_request(self, llm_request: Any) -> str:
        contents = getattr(llm_request, "contents", None)
        if not contents:
            return ""

        target_contents: list[Any] = []
        for content in reversed(contents):
            if getattr(content, "role", None) == "user":
                target_contents = [content]
                break
        if not target_contents:
            target_contents = list(contents)

        segments: list[str] = []
        for content in target_contents:
            role = getattr(content, "role", None) or "unknown"
            parts = getattr(content, "parts", None) or []
            for part in parts:
                entry = [role]
                text = getattr(part, "text", None)
                if text:
                    entry.append(text)

                func = getattr(part, "function_call", None)
                if func:
                    name = getattr(func, "name", "")
                    args = getattr(func, "args", {}) or {}
                    serialized_args = self._safe_json_dump(args)
                    entry.append(f"FUNC:{name}:{serialized_args}")

                file_data = getattr(part, "file_data", None)
                if file_data:
                    uri = getattr(file_data, "file_uri", "")
                    mime = getattr(file_data, "mime_type", "")
                    entry.append(f"FILE:{uri}:{mime}")

                if len(entry) > 1:
                    segments.append("|".join(entry))

        if not segments:
            return ""

        serialized = "\n".join(segments)
        return hashlib.sha256(serialized.encode("utf-8")).hexdigest()

    @staticmethod
    def _safe_json_dump(data: Any) -> str:
        try:
            return json.dumps(data, sort_keys=True, ensure_ascii=False)
        except TypeError:
            return json.dumps(str(data))

    def _extract_replay_subject(self, callback_context: Any) -> Tuple[str, str]:
        claims = self._get_auth_claims(callback_context, {}) if callback_context else {}
        email = str(
            claims.get("email")
            or claims.get("sub")
            or claims.get("user")
            or claims.get("principal")
            or ""
        ).strip()

        return email

    def _build_replay_key(self, email: str, payload_hash: str) -> str:
        return f"{email}|{payload_hash}"

    def _cleanup_replay_cache(self, now: float) -> None:
        expire_before = now - self._replay_ttl
        keys_to_delete = []
        for key, timestamp in self._replay_cache.items():
            if timestamp < expire_before:
                keys_to_delete.append(key)
            else:
                break
        for key in keys_to_delete:
            self._replay_cache.pop(key, None)

    # ------------------------------------------------------------------
    # Error sanitization helpers
    # ------------------------------------------------------------------
    def sanitize_error_message(self, message: str, *, audience: str = "user") -> str:
        sanitized = self._apply_secret_filters(message or "")
        if audience == "log":
            return sanitized

        condensed = sanitized.strip()
        if not condensed:
            return self._DEFAULT_USER_ERROR_MESSAGE

        if len(condensed) > 200:
            condensed = condensed[:200] + "..."

        return f"{self._DEFAULT_USER_ERROR_MESSAGE}\nì„¸ë¶€ ì •ë³´: {condensed}"

    def _apply_secret_filters(self, text: str) -> str:
        sanitized = text or ""
        for pattern, replacement in self._SECRET_PATTERNS:
            sanitized = pattern.sub(replacement, sanitized)
        sanitized = self._PATH_PATTERN.sub("<path>", sanitized)
        return sanitized

    def _sanitize_payload(self, payload: Any):
        if isinstance(payload, dict):
            return {key: self._sanitize_payload(value) for key, value in payload.items()}
        if isinstance(payload, list):
            return [self._sanitize_payload(item) for item in payload]
        if isinstance(payload, str):
            return self._apply_secret_filters(payload)
        return payload
