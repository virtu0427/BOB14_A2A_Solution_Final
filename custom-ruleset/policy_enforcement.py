"""Reusable IAM policy enforcement plugin for ADK-based agents."""

from __future__ import annotations

import contextlib
from contextvars import ContextVar
import hashlib
import json
import os
import re
import threading
import time
from collections import OrderedDict
from typing import Any, Dict, Iterable, Optional, Sequence, Tuple

import jwt
import google.generativeai as genai
import requests
from google.adk.plugins.base_plugin import BasePlugin

try:
    from google.genai.types import Content, Part
    from google.adk.models.llm_response import LlmResponse
except ImportError:
    Content = None
    Part = None
    LlmResponse = None


GLOBAL_REQUEST_TOKEN: ContextVar[str | None] = ContextVar(
    "global_request_token", default=None
)


class PolicyEnforcementPlugin(BasePlugin):
    """IAM ê¸°ë°˜ ì •ì±… ì§‘í–‰ í”ŒëŸ¬ê·¸ì¸."""

    _DEFAULT_MODEL = "gemini-2.0-flash"
    _DEFAULT_REPLAY_TTL_SECONDS = 5.0
    _DEFAULT_USER_ERROR_MESSAGE = "ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    _SECRET_PATTERNS = [
        (re.compile(r"(Authorization\s*:\s*Bearer\s+)[A-Za-z0-9\-\._~+/=]+", re.IGNORECASE), r"\1***"),
        (re.compile(r"(Bearer\s+)[A-Za-z0-9\-\._~+/=]+", re.IGNORECASE), r"\1***"),
        (re.compile(r"(api[_-]?key\s*[=:]\s*)([^\s]+)", re.IGNORECASE), r"\1***"),
        (re.compile(r"(token\s*[=:]\s*)([^\s]+)", re.IGNORECASE), r"\1***"),
        (re.compile(r"(secret\s*[=:]\s*)([^\s]+)", re.IGNORECASE), r"\1***"),
    ]
    _PATH_PATTERN = re.compile(r"((?:[A-Za-z]:)?[\\/][^\s]+)")

    def __init__(
        self,
        *,
        agent_id: str,
        gemini_api_key: Optional[str],
        policy_server_url: str,
        log_server_url: str,
        initial_auth_token: Optional[str] = None,
        initial_context: Optional[Any] = None,
    ) -> None:
        super().__init__(name=f"policy_enforcement_{agent_id}")
        self.agent_id = agent_id
        self.policy_server_url = policy_server_url.rstrip("/")
        self.log_server_url = log_server_url.rstrip("/")
        self.gemini_api_key = gemini_api_key
        self._models: Dict[str, Any] = {}
        
        # [Stateless] ì „ì—­ self.policy ëŒ€ì‹  ìºì‹œë§Œ ìœ ì§€
        self._policy_cache: Dict[str, Dict[str, Any]] = {}
        
        # [í•„ìˆ˜] ë ˆê±°ì‹œ í˜¸í™˜ì„± ë° ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•œ ë¹ˆ ê°ì²´
        self.policy: Dict[str, Any] = {}

        self._jwt_secret = os.getenv("JWT_SECRET") or os.getenv("SECRET_KEY")
        self._jwt_public_key = os.getenv("JWT_PUBLIC_KEY")
        self._jwt_algorithm = os.getenv("JWT_ALGORITHM") or os.getenv("ALGORITHM") or "HS256"
        self._jwt_audience = os.getenv("JWT_AUDIENCE")
        self._last_auth_token: str | None = None
        self._last_actor: str | None = None  # JWT subject/email ìºì‹œ (ë¡œê·¸ actorìš©)
        self._captured_token_hint: str | None = None
        self._last_policy_fetch_token: str | None = None
        self._replay_cache: "OrderedDict[str, float]" = OrderedDict()
        self._replay_lock = threading.Lock()
        ttl_env = os.getenv("POLICY_PLUGIN_REPLAY_TTL")
        try:
            self._replay_ttl = float(ttl_env) if ttl_env else self._DEFAULT_REPLAY_TTL_SECONDS
        except ValueError:
            self._replay_ttl = self._DEFAULT_REPLAY_TTL_SECONDS

        self._ingest_initial_auth(initial_auth_token, initial_context)

        if gemini_api_key:
            genai.configure(api_key=gemini_api_key)
            self._models[self._DEFAULT_MODEL] = genai.GenerativeModel(self._DEFAULT_MODEL)

    # ------------------------------------------------------------------
    # [ì•ˆì „ì¥ì¹˜] agent_executorê°€ í˜¸ì¶œí•˜ë”ë¼ë„ ì£½ì§€ ì•Šê²Œ ë¹ˆ ë©”ì„œë“œ ìœ ì§€
    # ------------------------------------------------------------------
    def fetch_policy(
        self,
        *,
        tool_context: Any = None,
        tool_args: Optional[Dict[str, Any]] = None,
        force: bool = False,
    ) -> None:
        pass

    # ------------------------------------------------------------------
    # Policy Cache Management (ëŸ°íƒ€ì„ ì •ì±… ìƒˆë¡œê³ ì¹¨)
    # ------------------------------------------------------------------
    def clear_policy_cache(self, tenant: Optional[str] = None) -> Dict[str, Any]:
        """
        ì •ì±… ìºì‹œë¥¼ ë¹„ì›ë‹ˆë‹¤. ë‹¤ìŒ ìš”ì²­ ì‹œ ìƒˆë¡œìš´ ì •ì±…ì„ APIì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
        
        Args:
            tenant: íŠ¹ì • í…Œë„ŒíŠ¸ë§Œ ìºì‹œë¥¼ ë¹„ìš°ë ¤ë©´ ì§€ì •. Noneì´ë©´ ì „ì²´ ìºì‹œ ë¹„ì›€.
        
        Returns:
            ìºì‹œ ë¹„ìš°ê¸° ê²°ê³¼ ì •ë³´
        """
        if tenant:
            # íŠ¹ì • í…Œë„ŒíŠ¸ë§Œ ìºì‹œ ë¹„ìš°ê¸°
            removed = []
            keys_to_remove = [k for k in self._policy_cache.keys() if tenant in k]
            for key in keys_to_remove:
                del self._policy_cache[key]
                removed.append(key)
            print(f"[PolicyPlugin][{self.agent_id}] ì •ì±… ìºì‹œ ë¹„ì›€ (tenant: {tenant}): {removed}")
            return {
                "agent_id": self.agent_id,
                "cleared": removed,
                "remaining_cache_size": len(self._policy_cache),
            }
        else:
            # ì „ì²´ ìºì‹œ ë¹„ìš°ê¸°
            cache_size = len(self._policy_cache)
            cleared_keys = list(self._policy_cache.keys())
            self._policy_cache.clear()
            print(f"[PolicyPlugin][{self.agent_id}] ì „ì²´ ì •ì±… ìºì‹œ ë¹„ì›€: {cache_size}ê°œ í•­ëª©")
            return {
                "agent_id": self.agent_id,
                "cleared": cleared_keys,
                "cleared_count": cache_size,
            }

    def get_cache_status(self) -> Dict[str, Any]:
        """í˜„ì¬ ì •ì±… ìºì‹œ ìƒíƒœë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return {
            "agent_id": self.agent_id,
            "cache_size": len(self._policy_cache),
            "cached_tenants": list(self._policy_cache.keys()),
        }

    # ------------------------------------------------------------------
    # Policy retrieval helpers
    # ------------------------------------------------------------------
    def _get_policy_for_tenant(self, tenant_str: str, user_email: str = "") -> Dict[str, Any]:
        """
        [HTTP API ëª¨ë“œ] í…Œë„ŒíŠ¸ ì •ì±…ì„ HTTP APIë¡œ ìš”ì²­í•˜ì—¬ ë¡œë“œ
        Docker í™˜ê²½ì„ ê³ ë ¤í•˜ì—¬ ì—¬ëŸ¬ URLì„ ì‹œë„
        user_emailì´ ì œê³µë˜ë©´ ê·¸ë£¹ ë©¤ë²„ì‹­ì„ í™•ì¸í•˜ì—¬ ê¶Œí•œ ì—†ëŠ” ê²½ìš° ë¹ˆ ì •ì±… ë°˜í™˜
        """
        # 1. ìºì‹œ í‚¤ì— user_email í¬í•¨ (ì‚¬ìš©ìë³„ ì •ì±… ìºì‹±)
        cache_key = f"{tenant_str}:{user_email}" if user_email else tenant_str
        if cache_key in self._policy_cache:
            return self._policy_cache[cache_key]

        merged_policy = {
            "template": "merged_policy",
            "tenant": tenant_str,
            "allowed_list": [] 
        }
        
        valid_targets = set()
        merged_agent_map = {}
        policy_found = False

        for tenant_read in tenant_str.split(","):
            tenant_clean = tenant_read.strip()
            if not tenant_clean: continue
            
            # API URL ì„¤ì • (í™˜ê²½ ë³€ìˆ˜ë¡œ ì œì–´ ê°€ëŠ¥, Docker í™˜ê²½ ê³ ë ¤)
            # ìš°ì„ ìˆœìœ„: í™˜ê²½ë³€ìˆ˜ > Docker ì„œë¹„ìŠ¤ëª… > host.docker.internal > localhost
            base_urls = [
                os.environ.get("POLICY_API_URL", "").rstrip("/"),  # í™˜ê²½ ë³€ìˆ˜
                "http://solution:3000",                            # Docker Compose ì„œë¹„ìŠ¤ëª…
                "http://attager-solution:3000",                    # Docker ì»¨í…Œì´ë„ˆëª…
                "http://host.docker.internal:3000",                # Docker Desktop
                "http://localhost:3000"                             # ë¡œì»¬ í™˜ê²½
            ]
            
            # ë¹ˆ ë¬¸ìì—´ ì œê±°
            base_urls = [url for url in base_urls if url]
            
            params = {
                "tenant": tenant_clean,
                "author": "security manager"
            }
            
            # ì‚¬ìš©ì ì´ë©”ì¼ ì „ë‹¬í•˜ì—¬ ê·¸ë£¹ ë©¤ë²„ì‹­ í™•ì¸
            if user_email:
                params["user"] = user_email
            
            data = None
            successful_url = None
            
            # ì—¬ëŸ¬ URLì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹œë„
            for base_url in base_urls:
                api_url = f"{base_url}/api/rulesets/tenant-template"
                try:
                    print(f"[DEBUG] ì •ì±… API ìš”ì²­ ì‹œë„: {api_url}?tenant={tenant_clean}&author=security+manager")
                    response = requests.get(api_url, params=params, timeout=5)
                    
                    if response.status_code == 200:
                        data = response.json()
                        successful_url = api_url
                        print(f"[DEBUG] âœ“ API ì‘ë‹µ ì„±ê³µ: {successful_url}")
                        break
                    else:
                        print(f"[DEBUG] âœ— HTTP {response.status_code} from {api_url}")
                        
                except requests.exceptions.Timeout:
                    print(f"[DEBUG] âœ— íƒ€ì„ì•„ì›ƒ: {api_url}")
                    continue
                except requests.exceptions.ConnectionError:
                    print(f"[DEBUG] âœ— ì—°ê²° ì‹¤íŒ¨: {api_url}")
                    continue
                except Exception as e:
                    print(f"[DEBUG] âœ— ì˜¤ë¥˜ ({api_url}): {e}")
                    continue
            
            # ë°ì´í„° ì²˜ë¦¬
            if data:
                policy_found = True
                raw_list = data.get("allowed_list", [])
                print(f"[DEBUG] API ì‘ë‹µ ìˆ˜ì‹  ì„±ê³µ. í•­ëª© ìˆ˜: {len(raw_list)}")
                
                for rule in raw_list:
                    raw_aid = rule.get("agent_id")
                    
                    if raw_aid:
                        # [Strict Mode] agent_idë¥¼ ìˆëŠ” ê·¸ëŒ€ë¡œ ì €ì¥ + ë³€í˜•ëœ ë³„ì¹­ë„ í•¨ê»˜ ì €ì¥
                        clean_aid = str(raw_aid).strip()
                        variants = self._id_variants(clean_aid)
                        valid_targets.update(variants)

                        tools = rule.get("allowed_tools", [])
                        if clean_aid in merged_agent_map:
                            existing_tools = set(merged_agent_map[clean_aid]["allowed_tools"])
                            existing_tools.update(tools)
                            merged_agent_map[clean_aid]["allowed_tools"] = list(existing_tools)
                        else:
                            merged_agent_map[clean_aid] = {
                                "agent_id": clean_aid,
                                "allowed_tools": list(set(tools))
                            }
            else:
                print(f"[ERROR] ëª¨ë“  API URL ì‹œë„ ì‹¤íŒ¨ (tenant: {tenant_clean}). ì‹œë„í•œ URL: {base_urls}")

        if policy_found:
            merged_policy["allowed_list"] = list(merged_agent_map.values())
            merged_policy["_valid_targets"] = valid_targets 
            
            self._policy_cache[cache_key] = merged_policy
            
            print(f"[DEBUG] ìµœì¢… ìŠ¹ì¸ëœ ì—ì´ì „íŠ¸ ëª©ë¡: {valid_targets}")
            return merged_policy
        
        return {}

    # ------------------------------------------------------------------
    # ADK callbacks
    # ------------------------------------------------------------------
    def _check_allowlist_rule(
        self,
        tool_name: str,
        policy: Dict[str, Any],
        tenant_id: str,
        tool_args: Dict[str, Any]
    ) -> Optional[str]:
        
        if not policy:
            return f"No policy defined for tenant '{tenant_id}'."

        allowed_list = policy.get("allowed_list", [])
        
        # 1. [ìê¸° ì‹ë³„] Strict Match (ëŒ€ì†Œë¬¸ì êµ¬ë¶„)
        my_id_strict = self.agent_id.strip()

        def _find_rule():
            for item in allowed_list:
                aid = str(item.get("agent_id", "")).strip()
                if not aid:
                    continue
                variants = self._id_variants(aid)  # ë‹¤ì–‘í•œ ë³„ì¹­(í’€ id, #agent ì´í›„, ë í† í°)ìœ¼ë¡œ í—ˆìš© ì²´í¬
                if my_id_strict in variants:
                    return item
            return None

        my_rule = _find_rule()

        if not my_rule:
            return f"Access Denied: Agent '{self.agent_id}' is not defined in the policy."

        # 2. [ë„êµ¬ ê¶Œí•œ í™•ì¸]
        my_allowed_tools = my_rule.get("allowed_tools", [])
        
        if tool_name not in my_allowed_tools:
            return f"Tool '{tool_name}' is NOT allowed for agent '{self.agent_id}'."

        # 3. [ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì „ìš©] call_remote_agent íƒ€ê²Ÿ ê²€ì¦
        if tool_name == "call_remote_agent":
            target_agent = tool_args.get("agent_name")
            if not target_agent:
                return "Missing 'agent_name' argument."
            
            # [ìˆ˜ì •ë¨] ì…ë ¥ëœ íƒ€ê²Ÿ ì´ë¦„ ê·¸ëŒ€ë¡œ + ë³„ì¹­ ë¹„êµ
            target_strict = str(target_agent).strip()
            variants = self._id_variants(target_strict)

            valid_targets = policy.get("_valid_targets", set())
            
            if variants.isdisjoint(valid_targets):
                return f"Access Denied: Target '{target_agent}' is not a valid agent in this tenant."

        return None

    @staticmethod
    def _id_variants(agent_id: str) -> set[str]:
        """ì—ì´ì „íŠ¸ ì‹ë³„ì ë§¤ì¹­ì„ ìœ„í•´ ê°€ëŠ¥í•œ ë³„ì¹­ ì§‘í•©ì„ ë§Œë“ ë‹¤."""
        variants = set()
        aid = (agent_id or "").strip()
        if not aid:
            return variants
        variants.add(aid)
        # '#agent:' ì´í›„ë§Œ ì¶”ì¶œ
        if "#agent:" in aid:
            variants.add(aid.split("#agent:", 1)[-1])
        # ':' ê¸°ì¤€ ë§ˆì§€ë§‰ í† í°
        if ":" in aid:
            variants.add(aid.split(":")[-1])
        return variants
    
    async def before_model_callback(
        self,
        *,
        callback_context: Any,
        llm_request: Any,
        **kwargs: Any,
    ) -> Optional[Any]:
        """Validate user prompts before the LLM is invoked."""
        self._capture_auth_from_context(callback_context)
        replay_block = await self._guard_soft_replay(callback_context or {}, llm_request)
        if replay_block is not None:
            return replay_block
        self.fetch_policy(tool_context=callback_context)
        if not self._policy_enabled():
            return None

        prompt_rules = self._get_prompt_rules()
        if not prompt_rules:
            return None

        user_prompt = self._extract_user_message(llm_request)
        if not user_prompt:
            return None

        rule = prompt_rules[0]
        system_prompt = rule.get("system_prompt", "")
        model_name = rule.get("model")

        verdict = await self._inspect_with_llm(system_prompt, user_prompt, model_name)
        print(f"[PolicyPlugin][{self.agent_id}] í”„ë¡¬í”„íŠ¸ íŒì •: {verdict}")

        if verdict != "SAFE":
            self._send_log(
                {
                    "source": "agent",
                    "agent_id": self.agent_id,
                    "policy_type": "prompt_validation",
                    "prompt": user_prompt,
                    "verdict": "VIOLATION",
                    "message": f"[{self.agent_id}] í”„ë¡¬í”„íŠ¸ ì •ì±… ìœ„ë°˜: ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ê°€ IAM ì •ì±…ì„ ìœ„ë°˜í–ˆìŠµë‹ˆë‹¤.",
                }
            )
            
            # LLMì„ ì‚¬ìš©í•˜ì—¬ ìœ ë™ì ì¸ ìœ„ë°˜ ì‘ë‹µ ìƒì„±
            violation_message = await self._generate_violation_response(
                violation_type="prompt_violation",
                violation_reason="ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ê°€ ì‹œìŠ¤í…œ ë³´ì•ˆ ì •ì±…ì„ ìœ„ë°˜",
                user_request=user_prompt,
                additional_context={"agent_id": self.agent_id},
                model_name=model_name,
            )
            
            return self._create_llm_response(violation_message)
        
        # ì •ìƒ í†µê³¼ ë¡œê·¸ ê¸°ë¡
        self._send_log(
            {
                "source": "agent",
                "agent_id": self.agent_id,
                "policy_type": "prompt_validation",
                "prompt": user_prompt[:100] + "..." if len(user_prompt) > 100 else user_prompt,
                "verdict": "PASS",
                "message": f"[{self.agent_id}] í”„ë¡¬í”„íŠ¸ ê²€ì¦ í†µê³¼",
            }
        )

        
        incoming_token = self._extract_auth_token(callback_context, {})
        
        if incoming_token:
            if hasattr(callback_context, "state") and isinstance(callback_context.state, dict):
                callback_context.state["auth_token"] = incoming_token
            elif hasattr(callback_context, "session") and hasattr(callback_context.session, "state"):
                 callback_context.session.state["auth_token"] = incoming_token
        
        return None

    async def before_tool_callback(
        self,
        *,
        tool: Any,
        tool_args: Dict[str, Any],
        tool_context: Any,
        callback_context: Any = None,
        **kwargs: Any,
    ) -> Optional[Dict[str, Any]]:
        
        ctx = callback_context or tool_context
        
        claims = self._get_auth_claims(ctx, tool_args)
        current_tenant = self._extract_tenant_from_claims(claims)
        # JWT í´ë ˆì„ì—ì„œ ì‚¬ìš©ì ì´ë©”ì¼ ì¶”ì¶œ (ê·¸ë£¹ ë©¤ë²„ì‹­ í™•ì¸ìš©)
        user_email = claims.get("sub") or claims.get("email") or claims.get("user") or ""

        if not current_tenant or current_tenant.startswith("<"):
            # LLMì„ ì‚¬ìš©í•˜ì—¬ ìœ ë™ì ì¸ ì ‘ê·¼ ê±°ë¶€ ì‘ë‹µ ìƒì„±
            access_denied_message = await self._generate_violation_response(
                violation_type="access_denied",
                violation_reason="ìœ íš¨í•œ í…Œë„ŒíŠ¸ ì •ë³´ ì—†ìŒ",
                additional_context={"tenant": current_tenant},
            )
            return {"error": access_denied_message}

        request_policy = self._get_policy_for_tenant(current_tenant, user_email=user_email)
        
        if not request_policy:
            # LLMì„ ì‚¬ìš©í•˜ì—¬ ìœ ë™ì ì¸ ì •ì±… ì—†ìŒ ì‘ë‹µ ìƒì„±
            no_policy_message = await self._generate_violation_response(
                violation_type="access_denied",
                violation_reason=f"í…Œë„ŒíŠ¸ '{current_tenant}'ì— ëŒ€í•œ ì •ì±… ì—†ìŒ",
                additional_context={"tenant": current_tenant},
            )
            return {"error": no_policy_message}

        tool_name = getattr(tool, "name", str(tool))
        
        violation = self._check_allowlist_rule(
            tool_name, 
            request_policy, 
            current_tenant, 
            tool_args
        )

        if violation:
            log_safe_violation = self.sanitize_error_message(violation, audience="log")
            self._send_log(
                {
                    "source": "agent",
                    "agent_id": self.agent_id,
                    "policy_type": "tool_validation",
                    "tool_name": tool_name,
                    "tool_args": tool_args,
                    "verdict": "BLOCKED",
                    "message": f"[{self.agent_id}] íˆ´ ì°¨ë‹¨: {log_safe_violation}",
                    "target_agent": tool_args.get("agent_name", ""),
                }
            )
            print(f"[PolicyPlugin][{self.agent_id}] íˆ´ ì°¨ë‹¨: {log_safe_violation}")
            
            # ìœ„ë°˜ ìœ í˜• íŒë³„
            target_agent = tool_args.get("agent_name", "")
            if "not a valid agent" in violation.lower() or "target" in violation.lower():
                violation_type = "target_not_allowed"
            elif "not allowed" in violation.lower() or "not defined" in violation.lower():
                violation_type = "tool_blocked"
            else:
                violation_type = "tool_blocked"
            
            # LLMì„ ì‚¬ìš©í•˜ì—¬ ìœ ë™ì ì¸ ìœ„ë°˜ ì‘ë‹µ ìƒì„±
            user_safe_message = await self._generate_violation_response(
                violation_type=violation_type,
                violation_reason=log_safe_violation,
                additional_context={
                    "tool_name": tool_name,
                    "target_agent": target_agent,
                    "tenant": current_tenant,
                    "agent_id": self.agent_id,
                },
            )
            
            return {"error": user_safe_message}

        # ì •ìƒ í†µê³¼ ë¡œê·¸ ê¸°ë¡
        self._send_log(
            {
                "source": "agent",
                "agent_id": self.agent_id,
                "policy_type": "tool_validation",
                "tool_name": tool_name,
                "verdict": "PASS",
                "message": f"[{self.agent_id}] íˆ´ ê²€ì¦ í†µê³¼: {tool_name}",
                "target_agent": tool_args.get("agent_name", ""),
            }
        )
        print(f"[PolicyPlugin] âœ… ìŠ¹ì¸ë¨({current_tenant}): {tool_name}")
        return None

    async def _guard_soft_replay(self, callback_context: Any, llm_request: Any) -> Optional[Any]:
        payload_hash = self._hash_llm_request(llm_request)
        if not payload_hash:
            return None

        email = self._extract_replay_subject(callback_context)
        if not email:
            return None

        key = self._build_replay_key(email, payload_hash)
        now = time.monotonic()
        replay_detected = False

        with self._replay_lock:
            self._cleanup_replay_cache(now)
            last_seen = self._replay_cache.get(key)
            if last_seen is None:
                self._replay_cache[key] = now
            else:
                if now - last_seen <= self._replay_ttl:
                    replay_detected = True
                else:
                    self._replay_cache[key] = now
            self._replay_cache.move_to_end(key)

        if not replay_detected:
            return None

        reason = "Repeated message payload detected within replay TTL"
        self._send_log(
            {
                "source": "agent",
                "agent_id": self.agent_id,
                "policy_type": "replay_protection",
                "verdict": "BLOCKED",
                "message": f"[{self.agent_id}] ë¦¬í”Œë ˆì´ ì°¨ë‹¨: {reason}",
                "tool_name": "",
            }
        )
        
        # LLMì„ ì‚¬ìš©í•˜ì—¬ ìœ ë™ì ì¸ ë¦¬í”Œë ˆì´ ì°¨ë‹¨ ì‘ë‹µ ìƒì„±
        user_prompt = self._extract_user_message(llm_request)
        violation_message = await self._generate_violation_response(
            violation_type="replay_blocked",
            violation_reason=reason,
            user_request=user_prompt,
            additional_context={"agent_id": self.agent_id, "email": email},
        )
        
        return self._create_llm_response(violation_message)

    # ... (ë‚˜ë¨¸ì§€ helper í•¨ìˆ˜ë“¤ì€ ê·¸ëŒ€ë¡œ ë‘ì„¸ìš”) ...
    # _policy_enabled, _get_prompt_rules, _get_tool_rules
    # _extract_user_message, _inspect_with_llm, _resolve_model
    # _check_tool_rule, _create_llm_response, _send_log
    # _ingest_initial_auth, _log_policy_fetch, _capture_auth_from_context
    # _extract_auth_token, _extract_token_from_container, _get_auth_claims
    # _decode_jwt, _log_token_inspection, _log_policy_binding
    # _normalize_required_roles, _extract_roles_from_claims
    # _extract_tenant_from_claims, _roles_satisfied, _sanitize_bearer

    # ------------------------------------------------------------------
    # Internal helpers
    # ------------------------------------------------------------------
    def _policy_enabled(self) -> bool:
        if not self.policy:
            return False
        enabled = self.policy.get("enabled", True)
        if isinstance(enabled, str):
            enabled = enabled.lower() not in {"false", "0", "off"}
        return bool(enabled)

    def _get_prompt_rules(self) -> Sequence[Dict[str, Any]]:
        rules = self.policy.get("prompt_validation_rules", []) or []
        if not rules:
            policies = self.policy.get("policies")
            if isinstance(policies, dict):
                prompt_validation = policies.get("prompt_validation") or {}
                system_prompt = prompt_validation.get("system_prompt", "")
                model = prompt_validation.get("model")
                enabled = prompt_validation.get("enabled", True)
                if system_prompt:
                    rules = [
                        {
                            "system_prompt": system_prompt,
                            "model": model,
                            "enabled": enabled,
                        }
                    ]

        enabled_rules = []
        for rule in rules:
            enabled = rule.get("enabled", True)
            if isinstance(enabled, str):
                enabled = enabled.lower() not in {"false", "0", "off"}
            if enabled and rule.get("system_prompt"):
                enabled_rules.append(rule)
        return enabled_rules

    def _get_tool_rules(self) -> Dict[str, Dict[str, Any]]:
        rules = self.policy.get("tool_validation_rules")

        if not rules:
            policies = self.policy.get("policies")
            if isinstance(policies, dict):
                tool_validation = policies.get("tool_validation") or {}
                enabled = tool_validation.get("enabled", True)
                if isinstance(enabled, str):
                    enabled = enabled.lower() not in {"false", "0", "off"}
                if not enabled:
                    return {}
                rules = tool_validation.get("rules")

        if isinstance(rules, dict):
            return rules
        return {}

    def _extract_user_message(self, llm_request: Any) -> str:
        message = ""
        if hasattr(llm_request, "contents") and llm_request.contents:
            for content in reversed(llm_request.contents):
                role = getattr(content, "role", None)
                if role == "user" and getattr(content, "parts", None):
                    for part in content.parts:
                        text = getattr(part, "text", None)
                        if text:
                            message += text
                    break
        return message

    async def _inspect_with_llm(
        self,
        system_prompt: str,
        user_prompt: str,
        model_name: Optional[str],
    ) -> str:
        if not system_prompt or not self.gemini_api_key:
            return "SAFE"

        model = self._resolve_model(model_name)
        if model is None:
            return "SAFE"

        try:
            inspect_prompt = (
                f"{system_prompt}\n\n"
                f"ê²€ì‚¬ ëŒ€ìƒ í”„ë¡¬í”„íŠ¸:\n\"{user_prompt}\"\n\n"
                "ì‘ë‹µì€ SAFE ë˜ëŠ” VIOLATION ë‘˜ ì¤‘ í•˜ë‚˜ë¡œë§Œ í•´ì£¼ì„¸ìš”."
            )
            response = model.generate_content([inspect_prompt])
            verdict = (response.text or "").strip().split()[0].upper()
            return verdict if verdict in {"SAFE", "VIOLATION"} else "SAFE"
        except Exception as exc:  # pragma: no cover - runtime LLM failures
            print(f"[PolicyPlugin] LLM ê²€ì¦ ì‹¤íŒ¨: {exc}")
            return "SAFE"

    def _resolve_model(self, model_name: Optional[str]):
        name = model_name or self._DEFAULT_MODEL
        if name in self._models:
            return self._models[name]
        if not self.gemini_api_key:
            return None
        try:
            model = genai.GenerativeModel(name)
            self._models[name] = model
            return model
        except Exception as exc:  # pragma: no cover - runtime model resolution issues
            print(f"[PolicyPlugin] ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨({name}): {exc}")
            return self._models.get(self._DEFAULT_MODEL)

    async def _generate_violation_response(
        self,
        violation_type: str,
        violation_reason: str,
        user_request: str = "",
        additional_context: Optional[Dict[str, Any]] = None,
        model_name: Optional[str] = None,
    ) -> str:
        """
        LLMì„ ì‚¬ìš©í•˜ì—¬ ì •ì±… ìœ„ë°˜ ìƒí™©ì— ë§ëŠ” ìœ ë™ì ì¸ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            violation_type: ìœ„ë°˜ ìœ í˜• (prompt_violation, tool_blocked, replay_blocked, access_denied ë“±)
            violation_reason: ìœ„ë°˜ ì‚¬ìœ  (ë‚´ë¶€ìš©, ì‚¬ìš©ìì—ê²Œ ì§ì ‘ ë…¸ì¶œí•˜ì§€ ì•ŠìŒ)
            user_request: ì‚¬ìš©ìì˜ ì›ë˜ ìš”ì²­ (ìˆëŠ” ê²½ìš°)
            additional_context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ (tool_name, target_agent ë“±)
            model_name: ì‚¬ìš©í•  ëª¨ë¸ëª… (ê¸°ë³¸ê°’: DEFAULT_MODEL)
        
        Returns:
            ì‚¬ìš©ì ì¹œí™”ì ì¸ ìœ„ë°˜ ì‘ë‹µ ë©”ì‹œì§€
        """
        # ê¸°ë³¸ í´ë°± ë©”ì‹œì§€ë“¤ (LLM í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ì‚¬ìš©)
        fallback_messages = {
            "prompt_violation": (
                "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­í•˜ì‹  ë‚´ìš©ì´ ì‹œìŠ¤í…œ ë³´ì•ˆ ì •ì±…ì— ë¶€í•©í•˜ì§€ ì•Šì•„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
                "ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì§ˆë¬¸í•´ ì£¼ì‹œê±°ë‚˜, ì •ì±…ì— ë§ëŠ” ìš”ì²­ì„ ì‹œë„í•´ ì£¼ì„¸ìš”."
            ),
            "tool_blocked": (
                "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­í•˜ì‹  ì‘ì—…ì„ ìˆ˜í–‰í•  ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤. "
                "í•„ìš”í•œ ê¶Œí•œì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì‹œê±°ë‚˜, ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ ì£¼ì„¸ìš”."
            ),
            "replay_blocked": (
                "ë™ì¼í•œ ìš”ì²­ì´ ë„ˆë¬´ ë¹ ë¥´ê²Œ ë°˜ë³µë˜ì–´ ì²˜ë¦¬ê°€ ì œí•œë˜ì—ˆìŠµë‹ˆë‹¤. "
                "ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
            ),
            "access_denied": (
                "ì ‘ê·¼ì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤. ìœ íš¨í•œ ì¸ì¦ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤. "
                "ë¡œê·¸ì¸ ìƒíƒœë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”."
            ),
            "target_not_allowed": (
                "ìš”ì²­í•˜ì‹  ëŒ€ìƒ ì—ì´ì „íŠ¸ì— ì ‘ê·¼í•  ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤. "
                "í—ˆìš©ëœ ì—ì´ì „íŠ¸ ëª©ë¡ì„ í™•ì¸í•´ ì£¼ì„¸ìš”."
            ),
        }
        
        default_fallback = (
            "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì •ì±… ì œí•œìœ¼ë¡œ ì¸í•´ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
            "ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì‹œë„í•˜ì‹œê±°ë‚˜ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ ì£¼ì„¸ìš”."
        )
        
        fallback = fallback_messages.get(violation_type, default_fallback)
        
        # Gemini APIê°€ ì—†ìœ¼ë©´ í´ë°± ë©”ì‹œì§€ ë°˜í™˜
        if not self.gemini_api_key:
            return fallback
        
        model = self._resolve_model(model_name)
        if model is None:
            return fallback
        
        # ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ì •ë¦¬
        ctx = additional_context or {}
        tool_name = ctx.get("tool_name", "")
        target_agent = ctx.get("target_agent", "")
        tenant = ctx.get("tenant", "")
        
        # LLMì—ê²Œ ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_instruction = """ë‹¹ì‹ ì€ AI ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì˜ ì •ì±… ì•ˆë‚´ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ìš”ì²­ì´ ì‹œìŠ¤í…œ ì •ì±…ì— ì˜í•´ ì œí•œë˜ì—ˆì„ ë•Œ, ì¹œì ˆí•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ìƒí™©ì„ ì„¤ëª…í•´ì•¼ í•©ë‹ˆë‹¤.

ì‘ë‹µ ì‘ì„± ê°€ì´ë“œë¼ì¸:
1. ì •ì¤‘í•˜ê³  ê³µê°ì ì¸ ì–´ì¡°ë¥¼ ìœ ì§€í•˜ì„¸ìš”
2. ì™œ ìš”ì²­ì´ ì œí•œë˜ì—ˆëŠ”ì§€ ê°„ë‹¨íˆ ì„¤ëª…í•˜ì„¸ìš” (ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­ì€ í”¼í•˜ì„¸ìš”)
3. ì‚¬ìš©ìê°€ ë‹¤ìŒì— ì–´ë–»ê²Œ í•  ìˆ˜ ìˆëŠ”ì§€ ëŒ€ì•ˆì„ ì œì‹œí•˜ì„¸ìš”
4. ì‘ë‹µì€ 2-4ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”
5. ë³´ì•ˆì— ë¯¼ê°í•œ ì •ë³´(í† í°, ë‚´ë¶€ ì˜¤ë¥˜, ì‹œìŠ¤í…œ ê²½ë¡œ ë“±)ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”
6. í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”"""

        context_parts = []
        context_parts.append(f"ìœ„ë°˜ ìœ í˜•: {violation_type}")
        
        if violation_type == "prompt_violation":
            context_parts.append("ìƒí™©: ì‚¬ìš©ìì˜ í”„ë¡¬í”„íŠ¸ê°€ ì‹œìŠ¤í…œ ë³´ì•ˆ ì •ì±…ì„ ìœ„ë°˜í–ˆìŠµë‹ˆë‹¤.")
        elif violation_type == "tool_blocked":
            context_parts.append(f"ìƒí™©: '{tool_name}' ë„êµ¬ ì‚¬ìš©ì´ í˜„ì¬ ì •ì±…ì—ì„œ í—ˆìš©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        elif violation_type == "replay_blocked":
            context_parts.append("ìƒí™©: ë™ì¼í•œ ìš”ì²­ì´ ì§§ì€ ì‹œê°„ ë‚´ì— ë°˜ë³µ ê°ì§€ë˜ì–´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        elif violation_type == "access_denied":
            context_parts.append("ìƒí™©: ì‚¬ìš©ìì˜ ì¸ì¦ ì •ë³´ê°€ ìœ íš¨í•˜ì§€ ì•Šê±°ë‚˜ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
        elif violation_type == "target_not_allowed":
            context_parts.append(f"ìƒí™©: '{target_agent}' ì—ì´ì „íŠ¸ì— ëŒ€í•œ ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.")
        
        if user_request:
            # ì‚¬ìš©ì ìš”ì²­ì€ ì²˜ìŒ 100ìë§Œ í¬í•¨ (ê°œì¸ì •ë³´ ë³´í˜¸)
            truncated_request = user_request[:100] + "..." if len(user_request) > 100 else user_request
            context_parts.append(f"ì‚¬ìš©ì ìš”ì²­ ìš”ì•½: {truncated_request}")
        
        context_str = "\n".join(context_parts)
        
        generation_prompt = f"""{system_instruction}

---
{context_str}
---

ìœ„ ìƒí™©ì— ëŒ€í•´ ì‚¬ìš©ìì—ê²Œ ì „ë‹¬í•  ì¹œì ˆí•œ ì•ˆë‚´ ë©”ì‹œì§€ë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”.
ì‘ë‹µì€ ì•ˆë‚´ ë©”ì‹œì§€ë§Œ í¬í•¨í•˜ê³ , ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ ë©”íƒ€ ì •ë³´ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."""

        try:
            response = model.generate_content([generation_prompt])
            generated_text = (response.text or "").strip()
            
            if generated_text and len(generated_text) > 10:
                # ìƒì„±ëœ ì‘ë‹µ ê²€ì¦ (ë¯¼ê° ì •ë³´ í¬í•¨ ì—¬ë¶€ ì²´í¬)
                sanitized = self._apply_secret_filters(generated_text)
                print(f"[PolicyPlugin] LLM ìœ„ë°˜ ì‘ë‹µ ìƒì„± ì™„ë£Œ ({violation_type})")
                return sanitized
            else:
                print(f"[PolicyPlugin] LLM ì‘ë‹µì´ ë„ˆë¬´ ì§§ìŒ, í´ë°± ì‚¬ìš©")
                return fallback
                
        except Exception as exc:
            print(f"[PolicyPlugin] LLM ìœ„ë°˜ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {exc}")
            return fallback

    def _check_tool_rule(
        self,
        tool_name: str,
        tool_args: Dict[str, Any],
        rule: Dict[str, Any],
        tool_context: Any,
    ) -> Optional[str]:
        allowed_agents = rule.get("allowed_agents")
        if allowed_agents:
            agent_name = tool_args.get("agent_name") or tool_args.get("agent")
            if agent_name and agent_name not in allowed_agents:
                return f"Agent '{agent_name}' is not allowed for {tool_name}"

        max_task_length = rule.get("max_task_length")
        if isinstance(max_task_length, int):
            task = tool_args.get("task", "") or ""
            if len(task) > max_task_length:
                return f"Task length ({len(task)}) exceeds maximum ({max_task_length})"

        requires_auth = rule.get("requires_auth")
        if isinstance(requires_auth, str):
            requires_auth = requires_auth.lower() not in {"false", "0", "off"}
        if requires_auth and not self._extract_auth_token(tool_context, tool_args):
            return "Authentication required for this tool"

        required_roles = rule.get("required_roles") or rule.get("required_role")
        normalized_roles = self._normalize_required_roles(required_roles)
        if normalized_roles:
            claims = self._get_auth_claims(tool_context, tool_args)
            user_roles = self._extract_roles_from_claims(claims)
            if not user_roles:
                return "Role information missing from JWT token"
            if not self._roles_satisfied(user_roles, normalized_roles):
                return f"Tool '{tool_name}' requires role(s): {', '.join(normalized_roles)}"

        max_results = rule.get("max_results")
        if isinstance(max_results, int):
            limit = tool_args.get("limit")
            if isinstance(limit, int) and limit > max_results:
                return f"Requested limit ({limit}) exceeds maximum ({max_results})"

        return None

    def _create_llm_response(self, message: str):
        if Content and Part and LlmResponse:
            try:
                response_content = Content(role="model", parts=[Part(text=message)])
                return LlmResponse(content=response_content)
            except Exception as exc:  # pragma: no cover
                print(f"[PolicyPlugin] LlmResponse ìƒì„± ì‹¤íŒ¨: {exc}")
        raise RuntimeError(message)

    def _send_log(self, payload: Dict[str, Any]) -> None:
        payload = self._sanitize_payload(dict(payload))
        if not payload.get("actor"):
            payload["actor"] = self._last_actor or ""
        log_url = f"{self.log_server_url}/api/logs"
        print(f"[PolicyPlugin] ğŸ“¤ ë¡œê·¸ ì „ì†¡ ì‹œë„: {log_url}")
        print(f"[PolicyPlugin] ğŸ“¦ í˜ì´ë¡œë“œ: {payload}")
        try:
            response = requests.post(
                log_url,
                json=payload,
                timeout=2,
            )
            print(f"[PolicyPlugin] âœ… ë¡œê·¸ ì „ì†¡ ê²°ê³¼: HTTP {response.status_code}")
            if response.status_code >= 400:
                print(f"[PolicyPlugin] âš ï¸ ë¡œê·¸ ì„œë²„ ì‘ë‹µ: {response.text[:200]}")
        except requests.exceptions.ConnectionError as e:
            print(f"[PolicyPlugin] âŒ ë¡œê·¸ ì„œë²„ ì—°ê²° ì‹¤íŒ¨ ({log_url}): {e}")
        except requests.exceptions.Timeout:
            print(f"[PolicyPlugin] â±ï¸ ë¡œê·¸ ì„œë²„ íƒ€ì„ì•„ì›ƒ ({log_url})")
        except Exception as e:
            print(f"[PolicyPlugin] âŒ ë¡œê·¸ ì „ì†¡ ì˜ˆì™¸: {type(e).__name__}: {e}")

    # ------------------------------------------------------------------
    # Authentication helpers
    # ------------------------------------------------------------------
    def _ingest_initial_auth(self, token_hint: Optional[str], context: Optional[Any]) -> None:
        env_token = (
            os.getenv("IAM_BOOTSTRAP_AUTH_TOKEN")
            or os.getenv("POLICY_BOOTSTRAP_TOKEN")
            or os.getenv("AUTH_TOKEN")
        )

        candidates = [token_hint, env_token, self._extract_token_from_container(context)]

        for candidate in candidates:
            cleaned = self._sanitize_bearer(candidate)
            if cleaned:
                self._captured_token_hint = cleaned
                self._last_auth_token = cleaned
                break

    def _log_policy_fetch(self, token: str) -> None:
        base_message = f"[PolicyPlugin] {self.agent_id} ì •ì±… ë¡œë“œ ì™„ë£Œ"

        if not token:
            print(f"{base_message} (auth_token=<none>)")
            return

        claims = self._decode_jwt(token)
        roles = self._extract_roles_from_claims(claims)
        tenant = self._extract_tenant_from_claims(claims)
        subject = claims.get("sub") or claims.get("email") or claims.get("user") or "<unknown>"
        token_preview = token if len(token) <= 18 else f"{token[:10]}...{token[-6:]}"
        print(f"{base_message} (subject={subject}, roles={roles or []}, tenant={tenant}, token={token_preview})")

    def _capture_auth_from_context(self, callback_context: Any) -> None:
        token = self._extract_token_from_container(callback_context)
        if token:
            self._captured_token_hint = token

    def _extract_auth_token(self, tool_context: Any, tool_args: Dict[str, Any]) -> str:
        # [ì§€ë¢° 3] í”ŒëŸ¬ê·¸ì¸ ë™ì‘ í™•ì¸ìš© ë¡œê·¸ (ê°ì²´ ë‚´ë¶€ êµ¬ì¡° ê³µê°œ)
        direct_token = GLOBAL_REQUEST_TOKEN.get()
        
        if direct_token:
            print(f"[3. Plugin] ContextVar ì§í†µ í„°ë„ì—ì„œ í† í° ë°œê²¬ ({direct_token[:10]}...)", flush=True)
            return self._sanitize_bearer(direct_token)
        # [ë””ë²„ê¹…] ë„ëŒ€ì²´ tool_context ì•ˆì— ë­ê°€ ë“¤ì—ˆëŠ”ì§€ ì†ì„±ì„ ë‹¤ ì°ì–´ë´…ë‹ˆë‹¤.
        try:
            attributes = dir(tool_context)
            # ë„ˆë¬´ ë§ìœ¼ë‹ˆ _ë¡œ ì‹œì‘í•˜ëŠ” ê±° ë¹¼ê³  ì¶œë ¥
            public_attrs = [a for a in attributes if not a.startswith('_')]
            print(f"[3. Plugin] Context ì†ì„± ëª©ë¡: {public_attrs}", flush=True)
        except:
            pass

        # ---------------------------------------------------------
        # [íƒìƒ‰ 1] Executorê°€ ë„£ì–´ë‘” ì„¸ì…˜ State ì°¾ê¸° (ê°•ë ¥í•œ íƒìƒ‰)
        # ---------------------------------------------------------
        possible_states = []

        # 1. tool_context.state
        if hasattr(tool_context, "state"):
            possible_states.append(tool_context.state)
        
        # 2. tool_context.session.state
        if hasattr(tool_context, "session"):
            session = getattr(tool_context, "session", None)
            if session and hasattr(session, "state"):
                possible_states.append(session.state)

        # 3. tool_context.context.state (ì¤‘ì²©ëœ ê²½ìš°)
        if hasattr(tool_context, "context"):
            inner_ctx = getattr(tool_context, "context", None)
            if inner_ctx:
                if hasattr(inner_ctx, "state"):
                    possible_states.append(inner_ctx.state)
                if hasattr(inner_ctx, "session") and hasattr(inner_ctx.session, "state"):
                    possible_states.append(inner_ctx.session.state)

        # 4. (ì¶”ê°€) attributes ë”•ì…”ë„ˆë¦¬ í™•ì¸
        if hasattr(tool_context, "attributes") and isinstance(tool_context.attributes, dict):
             possible_states.append(tool_context.attributes)

        # ìˆ˜ì§‘ëœ ëª¨ë“  state í›„ë³´êµ°ì„ ë’¤ì ¸ì„œ í† í° ì°¾ê¸°
        for state in possible_states:
            if not state: continue
            
            # dictì¸ ê²½ìš°
            if isinstance(state, dict):
                token = state.get("auth_token")
                if token:
                    print(f"[3. Plugin] â­• (Dict State) í† í°: {token[:10]}...", flush=True)
                    return self._sanitize_bearer(token)
            # objectì¸ ê²½ìš°
            elif hasattr(state, "auth_token"):
                token = getattr(state, "auth_token")
                if token:
                    print(f"[3. Plugin] â­• ì°¾ì•˜ë‹¤! (Obj State) í† í°: {token[:10]}...", flush=True)
                    return self._sanitize_bearer(token)

        # ---------------------------------------------------------
        # [íƒìƒ‰ 2] ë„êµ¬ ì¸ì(Arguments)ì—ì„œ ì°¾ê¸°
        # ---------------------------------------------------------
        tool_args = tool_args or {}
        candidates = [
            tool_args.get("auth_token"),
            tool_args.get("token"),
            tool_args.get("Authorization"),
            tool_args.get("authorization"),
        ]

        # ---------------------------------------------------------
        # [íƒìƒ‰ 3] ê¸°íƒ€ ì»¨í…Œì´ë„ˆ ì¬ê·€ íƒìƒ‰ (í—¤ë” ë“±)
        # ---------------------------------------------------------
        candidates.append(self._extract_token_from_container(tool_context))
        candidates.append(self._extract_token_from_container(getattr(tool_context, "metadata", None)))

        if self._captured_token_hint:
            candidates.append(self._captured_token_hint)

        if self._last_auth_token:
            candidates.append(self._last_auth_token)

        for candidate in candidates:
            cleaned = self._sanitize_bearer(candidate)
            if cleaned:
                print(f"[3. Plugin] â­• (Container/Args) í† í°: {cleaned[:10]}...", flush=True)
                return cleaned
        
        print(f"[3. Plugin] âŒ ì‹¤íŒ¨: í† í°ì´ ì—†ìŠµë‹ˆë‹¤.", flush=True)
        return ""

    def _extract_token_from_container(self, container: Any, _visited: Optional[set[int]] = None) -> str:
        # [ë””ë²„ê¹…] ë“¤ì–´ì˜¤ëŠ” ìš”ì²­ì˜ í—¤ë”ë¥¼ í›”ì³ë³´ì
        if isinstance(container, dict) and "auth_token" in container:
             print(f"[3. Plugin] ì»¨í…Œì´ë„ˆ ì•ˆì— auth_token ìˆìŒ: {str(container.get('auth_token'))[:10]}...", flush=True)
        if not container:
            return ""

        if _visited is None:
            _visited = set()

        ident = id(container)
        if ident in _visited:
            return ""
        _visited.add(ident)

        if isinstance(container, dict):
            headers = container.get("headers") or container
            for key in ("Authorization", "authorization", "auth_token", "token"):
                if key in headers:
                    return self._sanitize_bearer(headers.get(key))

            for nested_key in (
                "headers",
                "metadata",
                "context",
                "raw_request",
                "request",
                "envelope",
            ):
                nested = headers.get(nested_key)
                cleaned = self._extract_token_from_container(nested, _visited)
                if cleaned:
                    return cleaned

            for value in headers.values():
                cleaned = self._extract_token_from_container(value, _visited)
                if cleaned:
                    return cleaned

        if isinstance(container, (list, tuple, set)):
            for item in container:
                cleaned = self._extract_token_from_container(item, _visited)
                if cleaned:
                    return cleaned

        for attr in ("headers", "metadata", "context", "raw_request", "request"):
            candidate = getattr(container, attr, None)
            cleaned = self._extract_token_from_container(candidate, _visited)
            if cleaned:
                return cleaned

        return ""

    def _get_auth_claims(self, tool_context: Any, tool_args: Dict[str, Any]) -> Dict[str, Any]:
        token = self._extract_auth_token(tool_context, tool_args)
        if not token:
            self._last_actor = None
            return {}
        claims = self._decode_jwt(token)
        if claims:
            actor = self._extract_actor_from_claims(claims)
            self._last_actor = actor or None
            repeated_token = token == self._last_auth_token
            self._log_token_inspection(token, claims, repeated=repeated_token)
            self._log_policy_binding(token, claims)
            self._last_auth_token = token
        else:
            self._last_actor = None
        return claims

    def _decode_jwt(self, token: str) -> Dict[str, Any]:
        options = {"verify_signature": bool(self._jwt_secret or self._jwt_public_key)}
        verify_args: Dict[str, Any] = {"algorithms": [self._jwt_algorithm]}

        if self._jwt_audience:
            verify_args["audience"] = self._jwt_audience

        key = self._jwt_public_key or self._jwt_secret
        try:
            if key:
                return jwt.decode(token, key=key, options=options, **verify_args)
            return jwt.decode(token, options={"verify_signature": False})
        except Exception as exc:  # pragma: no cover - runtime token parsing
            print(f"[PolicyPlugin] JWT decode ì‹¤íŒ¨: {exc}")
            return {}

    def _log_token_inspection(self, token: str, claims: Dict[str, Any], *, repeated: bool = False) -> None:
        roles = self._extract_roles_from_claims(claims)
        subject = claims.get("sub") or claims.get("email") or claims.get("user")
        token_preview = token if len(token) <= 18 else f"{token[:10]}...{token[-6:]}"
        event = "JWT ì¬ì‚¬ìš©" if repeated else "JWT ë¡œë“œ"
        print(
            "[PolicyPlugin][{}] {}: sub={}, roles={}, token={}".format(
                self.agent_id, event, subject or "<unknown>", roles or [], token_preview
            )
        )

    def _log_policy_binding(self, token: str, claims: Dict[str, Any]) -> None:
        roles = self._extract_roles_from_claims(claims)
        subject = claims.get("sub") or claims.get("email") or claims.get("user") or "<unknown>"
        token_preview = token if len(token) <= 18 else f"{token[:10]}...{token[-6:]}"
        rule_keys = sorted(self._get_tool_rules().keys())
        rule_summary = ", ".join(rule_keys) if rule_keys else "<no tool rules>"
        print(
            "[PolicyPlugin][{}] ì •ì±… ì ìš©: subject={}, roles={}, token={}, rules={}".format(
                self.agent_id, subject, roles or [], token_preview, rule_summary
            )
        )

    def _normalize_required_roles(self, required_roles: Any) -> list[str]:
        if not required_roles:
            return []
        if isinstance(required_roles, str):
            required_roles = [required_roles]
        if isinstance(required_roles, Iterable):
            return [str(role).strip().lower() for role in required_roles if str(role).strip()]
        return []

    def _extract_roles_from_claims(self, claims: Dict[str, Any]) -> list[str]:
        if not isinstance(claims, dict):
            return []
        roles: list[str] = []
        for key in ("roles", "role", "permissions", "scopes", "scope"):
            value = claims.get(key)
            if isinstance(value, str):
                roles.extend(item.strip().lower() for item in value.split() if item.strip())
            elif isinstance(value, Iterable):
                roles.extend(str(item).strip().lower() for item in value if str(item).strip())
        return roles

    @staticmethod
    def _extract_actor_from_claims(claims: Dict[str, Any]) -> str:
        if not isinstance(claims, dict):
            return ""
        for key in ("sub", "email", "user", "principal"):
            value = claims.get(key)
            if value:
                return str(value)
        return ""

    def _extract_tenant_from_claims(self, claims: Dict[str, Any]) -> str:
        """
        Pydantic ìŠ¤í‚¤ë§ˆ(TenantValue)ì— ë§ì¶° í…Œë„ŒíŠ¸ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        Target Key: "tenant"
        Type: str | List[str]
        """
        if not isinstance(claims, dict):
            return "<unknown_tenant>"

        # 1. ìŠ¤í‚¤ë§ˆì— ì •ì˜ëœ ì •í™•í•œ í‚¤ 'tenant'ë¥¼ ìš°ì„  í™•ì¸
        # ì„œë²„ ìŠ¤í‚¤ë§ˆ: class TokenData(BaseModel): tenant: TenantValue | None
        val = claims.get("tenant")

        # 2. ê°’ì´ ì—†ëŠ” ê²½ìš°, ê´€ë¡€ì ì¸ ë‹¤ë¥¸ í‚¤ë“¤ë„ í™•ì¸ (í˜¹ì‹œ ëª¨ë¥´ë‹ˆ)
        if val is None:
            for fallback_key in ["tid", "tenant_id", "org_id"]:
                val = claims.get(fallback_key)
                if val: break
        
        if val is None:
            return "<no_tenant>"

        def _clean_tenant_value(v: Any) -> str:
            """tenant ê°’ì—ì„œ ë¶ˆí•„ìš”í•œ ë”°ì˜´í‘œì™€ ê³µë°±ì„ ì œê±°í•©ë‹ˆë‹¤."""
            s = str(v).strip()
            # ì–‘ìª½ ë”°ì˜´í‘œ ì œê±° (JSON ì§ë ¬í™” ë¬¸ì œ ëŒ€ì‘)
            if (s.startswith('"') and s.endswith('"')) or (s.startswith("'") and s.endswith("'")):
                s = s[1:-1].strip()
            return s

        # 3. TenantValue = Union[str, List[str]] ì²˜ë¦¬
        if isinstance(val, list):
            # ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°: ê° ê°’ì„ ì •ë¦¬í•˜ê³  ì½¤ë§ˆë¡œ ì—°ê²°
            cleaned = [_clean_tenant_value(v) for v in val if v]
            return ",".join(cleaned)
        
        return _clean_tenant_value(val)

    def _roles_satisfied(self, user_roles: list[str], required_roles: list[str]) -> bool:
        user_role_set = {role.lower() for role in user_roles}
        return any(role.lower() in user_role_set for role in required_roles)

    @staticmethod
    def _sanitize_bearer(token: Any) -> str:
        if not token:
            return ""
        token_str = str(token).strip()
        if token_str.lower().startswith("bearer "):
            return token_str[7:].strip()
        return token_str

    # ------------------------------------------------------------------
    # Soft replay helpers
    # ------------------------------------------------------------------
    def _hash_llm_request(self, llm_request: Any) -> str:
        contents = getattr(llm_request, "contents", None)
        if not contents:
            return ""

        target_contents: list[Any] = []
        for content in reversed(contents):
            if getattr(content, "role", None) == "user":
                target_contents = [content]
                break
        if not target_contents:
            target_contents = list(contents)

        segments: list[str] = []
        for content in target_contents:
            role = getattr(content, "role", None) or "unknown"
            parts = getattr(content, "parts", None) or []
            for part in parts:
                entry = [role]
                text = getattr(part, "text", None)
                if text:
                    entry.append(text)

                func = getattr(part, "function_call", None)
                if func:
                    name = getattr(func, "name", "")
                    args = getattr(func, "args", {}) or {}
                    serialized_args = self._safe_json_dump(args)
                    entry.append(f"FUNC:{name}:{serialized_args}")

                file_data = getattr(part, "file_data", None)
                if file_data:
                    uri = getattr(file_data, "file_uri", "")
                    mime = getattr(file_data, "mime_type", "")
                    entry.append(f"FILE:{uri}:{mime}")

                if len(entry) > 1:
                    segments.append("|".join(entry))

        if not segments:
            return ""

        serialized = "\n".join(segments)
        return hashlib.sha256(serialized.encode("utf-8")).hexdigest()

    @staticmethod
    def _safe_json_dump(data: Any) -> str:
        try:
            return json.dumps(data, sort_keys=True, ensure_ascii=False)
        except TypeError:
            return json.dumps(str(data))

    def _extract_replay_subject(self, callback_context: Any) -> Tuple[str, str]:
        claims = self._get_auth_claims(callback_context, {}) if callback_context else {}
        email = str(
            claims.get("email")
            or claims.get("sub")
            or claims.get("user")
            or claims.get("principal")
            or ""
        ).strip()

        return email

    def _build_replay_key(self, email: str, payload_hash: str) -> str:
        return f"{email}|{payload_hash}"

    def _cleanup_replay_cache(self, now: float) -> None:
        expire_before = now - self._replay_ttl
        keys_to_delete = []
        for key, timestamp in self._replay_cache.items():
            if timestamp < expire_before:
                keys_to_delete.append(key)
            else:
                break
        for key in keys_to_delete:
            self._replay_cache.pop(key, None)

    # ------------------------------------------------------------------
    # Error sanitization helpers
    # ------------------------------------------------------------------
    def sanitize_error_message(self, message: str, *, audience: str = "user") -> str:
        sanitized = self._apply_secret_filters(message or "")
        if audience == "log":
            return sanitized

        condensed = sanitized.strip()
        if not condensed:
            return self._DEFAULT_USER_ERROR_MESSAGE

        if len(condensed) > 200:
            condensed = condensed[:200] + "..."

        return f"{self._DEFAULT_USER_ERROR_MESSAGE}\nì„¸ë¶€ ì •ë³´: {condensed}"

    def _apply_secret_filters(self, text: str) -> str:
        sanitized = text or ""
        for pattern, replacement in self._SECRET_PATTERNS:
            sanitized = pattern.sub(replacement, sanitized)
        sanitized = self._PATH_PATTERN.sub("<path>", sanitized)
        return sanitized

    def _sanitize_payload(self, payload: Any):
        if isinstance(payload, dict):
            return {key: self._sanitize_payload(value) for key, value in payload.items()}
        if isinstance(payload, list):
            return [self._sanitize_payload(item) for item in payload]
        if isinstance(payload, str):
            return self._apply_secret_filters(payload)
        return payload
